{
  "resolvedId": "D:/hub2023A/itwinjs-core/core/frontend/lib/esm/render/webgl/CachedGeometry.js",
  "transforms": [
    {
      "name": "vite:load-fallback",
      "result": "/*---------------------------------------------------------------------------------------------\n* Copyright (c) Bentley Systems, Incorporated. All rights reserved.\n* See LICENSE.md in the project root for license terms and full copyright notice.\n*--------------------------------------------------------------------------------------------*/\n/** @packageDocumentation\n * @module WebGL\n */\nimport { assert, dispose } from \"@itwin/core-bentley\";\nimport { Angle, Point2d, Point3d, Range3d, Vector3d } from \"@itwin/core-geometry\";\nimport { Npc, QParams2d, QParams3d, QPoint2dList, QPoint3dList, RenderMode } from \"@itwin/core-common\";\nimport { FlashMode } from \"../../FlashSettings\";\nimport { RenderMemory } from \"../RenderMemory\";\nimport { AttributeMap } from \"./AttributeMap\";\nimport { LineCode } from \"./LineCode\";\nimport { fromSumOf } from \"./FrustumUniforms\";\nimport { GL } from \"./GL\";\nimport { BufferHandle, BufferParameters, BuffersContainer, QBufferHandle2d, QBufferHandle3d } from \"./AttributeBuffers\";\nimport { System } from \"./System\";\nimport { computeCompositeTechniqueId } from \"./TechniqueId\";\nimport { TextureHandle } from \"./Texture\";\nconst scratchVec3a = new Vector3d();\nconst scratchVec3b = new Vector3d();\nconst scratchVec3c = new Vector3d();\nconst scratchPoint3a = new Point3d();\nconst scratchPoint3b = new Point3d();\nconst scratchPoint3c = new Point3d();\nconst scratchPoint3d = new Point3d();\n/** Represents a geometric primitive ready to be submitted to the GPU for rendering.\n * @internal\n */\nexport class CachedGeometry {\n    /**\n     * Functions for obtaining a subclass of CachedGeometry.\n     * IMPORTANT: Do NOT use code like `const surface = cachedGeom as SurfaceGeometry`.\n     * Instanced geometry holds a reference to the shared geometry rendered for each instance - such casts will fail,\n     * while the casting `functions` will forward to the shared geometry.\n     */\n    get asLUT() { return undefined; }\n    get asSurface() { return undefined; }\n    get asMesh() { return undefined; }\n    get asEdge() { return undefined; }\n    get asIndexedEdge() { return undefined; }\n    get asRealityMesh() { return undefined; }\n    get asSilhouette() { return undefined; }\n    get asInstanced() { return undefined; }\n    get isInstanced() { return undefined !== this.asInstanced; }\n    get asPointCloud() { return undefined; }\n    get asPlanarGrid() { return undefined; }\n    get alwaysRenderTranslucent() { return false; }\n    get allowColorOverride() { return true; }\n    // Returns the edge/line weight used to render this geometry\n    _getLineWeight(_params) { return 0; }\n    // Returns the edge/line pattern used to render this geometry\n    _getLineCode(_params) { return LineCode.solid; }\n    // Returns true if this is a lit surface\n    get isLitSurface() { return false; }\n    // Returns true if this is an unlit surface with baked-in lighting (e.g. 3mx, scalable mesh reality models)\n    get hasBakedLighting() { return false; }\n    // Returns true if this primitive contains auxillary animation data.\n    get hasAnimation() { return false; }\n    /** If false, the geometry's positions are not quantized.\n     * qOrigin and qScale can still be used to derive the geometry's range, but will not be passed to the shader.\n     * see VertexLUT.usesQuantizedPositions.\n     */\n    get usesQuantizedPositions() { return true; }\n    // Intended to be overridden by specific subclasses\n    get materialInfo() { return undefined; }\n    get hasMaterialAtlas() {\n        const mat = this.materialInfo;\n        return undefined !== mat && mat.isAtlas;\n    }\n    get polylineBuffers() { return undefined; }\n    get hasFeatures() { return false; }\n    get viewIndependentOrigin() { return undefined; }\n    get isViewIndependent() { return undefined !== this.viewIndependentOrigin; }\n    get supportsThematicDisplay() { return false; }\n    get isEdge() {\n        switch (this.renderOrder) {\n            case 6 /* RenderOrder.Edge */:\n            case 7 /* RenderOrder.Silhouette */:\n            case 14 /* RenderOrder.PlanarEdge */:\n            case 15 /* RenderOrder.PlanarSilhouette */:\n                return true;\n            default:\n                return false;\n        }\n    }\n    wantWoWReversal(params) {\n        return params.target.currentViewFlags.whiteOnWhiteReversal && this._wantWoWReversal(params.target);\n    }\n    getLineCode(params) {\n        return params.target.currentViewFlags.styles ? this._getLineCode(params) : LineCode.solid;\n    }\n    getLineWeight(params) {\n        if (!params.target.currentViewFlags.weights) {\n            return 1.0;\n        }\n        const minWeight = 1;\n        let weight = this._getLineWeight(params);\n        weight = Math.max(weight, minWeight);\n        weight = Math.min(weight, 31.0);\n        return weight;\n    }\n    getFlashMode(params) {\n        // By default only surfaces rendered with lighting get brightened. Overridden for reality meshes since they have lighting baked-in.\n        // NB: If the reality model is classified, the classifiers are drawn without lighting, therefore we mix the hilite color.\n        if (this.hasBakedLighting)\n            return FlashMode.Hilite;\n        const vf = params.target.currentViewFlags;\n        if (!this.isLitSurface || RenderMode.SmoothShade !== vf.renderMode)\n            return FlashMode.Hilite;\n        return vf.lighting ? params.target.plan.flashSettings.litMode : FlashMode.Hilite;\n    }\n    wantMixMonochromeColor(_target) { return false; }\n    wantMonochrome(_target) { return true; }\n    computeRange(output) {\n        if (undefined === this._range) {\n            const lowX = this.qOrigin[0];\n            const lowY = this.qOrigin[1];\n            const lowZ = this.qOrigin[2];\n            const hiX = 0xffff * this.qScale[0] + lowX;\n            const hiY = 0xffff * this.qScale[1] + lowY;\n            const hiZ = 0xffff * this.qScale[2] + lowZ;\n            this._range = Range3d.createXYZXYZ(lowX, lowY, lowZ, hiX, hiY, hiZ);\n        }\n        return this._range.clone(output);\n    }\n}\n/** Geometry which is drawn using indices into a look-up texture of vertex data, via gl.drawArrays()\n * @internal\n */\nexport class LUTGeometry extends CachedGeometry {\n    get asLUT() { return this; }\n    get viewIndependentOrigin() { return this._viewIndependentOrigin; }\n    draw() { this._draw(0); }\n    drawInstanced(numInstances, instanceBuffersContainer) { this._draw(numInstances, instanceBuffersContainer); }\n    // Override this if your color varies based on the target\n    getColor(_target) { return this.lut.colorInfo; }\n    get usesQuantizedPositions() { return this.lut.usesQuantizedPositions; }\n    get qOrigin() { return this.lut.qOrigin; }\n    get qScale() { return this.lut.qScale; }\n    get hasAnimation() { return this.lut.hasAnimation; }\n    constructor(viewIndependentOrigin) {\n        super();\n        this._viewIndependentOrigin = viewIndependentOrigin;\n    }\n}\n/** Parameters used to construct an IndexedGeometry\n * @internal\n */\nexport class IndexedGeometryParams {\n    constructor(positions, indices, numIndices) {\n        this.buffers = BuffersContainer.create();\n        const attrPos = AttributeMap.findAttribute(\"a_pos\", undefined, false);\n        assert(attrPos !== undefined);\n        this.buffers.addBuffer(positions, [BufferParameters.create(attrPos.location, 3, GL.DataType.UnsignedShort, false, 0, 0, false)]);\n        this.buffers.addBuffer(indices, []);\n        this.positions = positions;\n        this.indices = indices;\n        this.numIndices = numIndices;\n    }\n    static create(positions, qParams, indices) {\n        const posBuf = QBufferHandle3d.create(qParams, positions);\n        const indBuf = BufferHandle.createBuffer(GL.Buffer.Target.ElementArrayBuffer, indices);\n        if (undefined === posBuf || undefined === indBuf)\n            return undefined;\n        return new IndexedGeometryParams(posBuf, indBuf, indices.length);\n    }\n    static createFromList(positions, indices) {\n        return IndexedGeometryParams.create(positions.toTypedArray(), positions.params, indices);\n    }\n    get isDisposed() {\n        return this.buffers.isDisposed\n            && this.positions.isDisposed\n            && this.indices.isDisposed;\n    }\n    dispose() {\n        dispose(this.buffers);\n        dispose(this.positions);\n        dispose(this.indices);\n    }\n}\n/** A geometric primitive which is rendered using gl.drawElements() with one or more vertex buffers indexed by an index buffer.\n * @internal\n */\nexport class IndexedGeometry extends CachedGeometry {\n    _wantWoWReversal(_target) { return false; }\n    constructor(params) {\n        super();\n        this._params = params;\n    }\n    get isDisposed() { return this._params.isDisposed; }\n    dispose() {\n        dispose(this._params);\n    }\n    draw() {\n        this._params.buffers.bind();\n        System.instance.context.drawElements(GL.PrimitiveType.Triangles, this._params.numIndices, GL.DataType.UnsignedInt, 0);\n        this._params.buffers.unbind();\n    }\n    get qOrigin() { return this._params.positions.origin; }\n    get qScale() { return this._params.positions.scale; }\n}\n/** a cube of quads in normalized device coordinates for skybox rendering techniques\n * @internal\n */\nclass SkyBoxQuads {\n    constructor() {\n        const skyBoxSz = 1.0;\n        const qVerts = new QPoint3dList(QParams3d.fromNormalizedRange());\n        // NB: After applying the rotation matrix in the shader, Back becomes (Bottom), etc.\n        // See the notes in the parens below.\n        // ###TODO: Make this indexed.  Currently not indexed because of previous six-sided texture system.\n        // Back (Bottom after rotation)\n        qVerts.add(new Point3d(-skyBoxSz, skyBoxSz, skyBoxSz)); // back upper left - 0\n        qVerts.add(new Point3d(skyBoxSz, skyBoxSz, skyBoxSz)); // back upper right - 1\n        qVerts.add(new Point3d(-skyBoxSz, -skyBoxSz, skyBoxSz)); // back lower left - 2\n        qVerts.add(new Point3d(skyBoxSz, skyBoxSz, skyBoxSz)); // back upper right - 1\n        qVerts.add(new Point3d(skyBoxSz, -skyBoxSz, skyBoxSz)); // back lower right - 3\n        qVerts.add(new Point3d(-skyBoxSz, -skyBoxSz, skyBoxSz)); // back lower left - 2\n        // Front (Top after rotation)\n        qVerts.add(new Point3d(-skyBoxSz, skyBoxSz, -skyBoxSz)); // front upper left - 4\n        qVerts.add(new Point3d(skyBoxSz, skyBoxSz, -skyBoxSz)); // front upper right - 5\n        qVerts.add(new Point3d(-skyBoxSz, -skyBoxSz, -skyBoxSz)); // front lower left - 6\n        qVerts.add(new Point3d(skyBoxSz, skyBoxSz, -skyBoxSz)); // front upper right - 5\n        qVerts.add(new Point3d(skyBoxSz, -skyBoxSz, -skyBoxSz)); // front lower right - 7\n        qVerts.add(new Point3d(-skyBoxSz, -skyBoxSz, -skyBoxSz)); // front lower left - 6\n        // Top (Front after rotation)\n        qVerts.add(new Point3d(-skyBoxSz, skyBoxSz, -skyBoxSz)); // front upper left - 4\n        qVerts.add(new Point3d(skyBoxSz, skyBoxSz, -skyBoxSz)); // front upper right - 5\n        qVerts.add(new Point3d(skyBoxSz, skyBoxSz, skyBoxSz)); // back upper right - 1\n        qVerts.add(new Point3d(-skyBoxSz, skyBoxSz, -skyBoxSz)); // front upper left - 4\n        qVerts.add(new Point3d(-skyBoxSz, skyBoxSz, skyBoxSz)); // back upper left - 0\n        qVerts.add(new Point3d(skyBoxSz, skyBoxSz, skyBoxSz)); // back upper right - 1\n        // Bottom (Back after rotation)\n        qVerts.add(new Point3d(-skyBoxSz, -skyBoxSz, skyBoxSz)); // back lower left - 2\n        qVerts.add(new Point3d(skyBoxSz, -skyBoxSz, skyBoxSz)); // back lower right - 3\n        qVerts.add(new Point3d(-skyBoxSz, -skyBoxSz, -skyBoxSz)); // front lower left - 6\n        qVerts.add(new Point3d(skyBoxSz, -skyBoxSz, skyBoxSz)); // back lower right - 3\n        qVerts.add(new Point3d(skyBoxSz, -skyBoxSz, -skyBoxSz)); // front lower right - 7\n        qVerts.add(new Point3d(-skyBoxSz, -skyBoxSz, -skyBoxSz)); // front lower left - 6\n        // Left (Right after rotation)\n        qVerts.add(new Point3d(-skyBoxSz, skyBoxSz, skyBoxSz)); // back upper left - 0\n        qVerts.add(new Point3d(-skyBoxSz, skyBoxSz, -skyBoxSz)); // front upper left - 4\n        qVerts.add(new Point3d(-skyBoxSz, -skyBoxSz, skyBoxSz)); // back lower left - 2\n        qVerts.add(new Point3d(-skyBoxSz, skyBoxSz, -skyBoxSz)); // front upper left - 4\n        qVerts.add(new Point3d(-skyBoxSz, -skyBoxSz, -skyBoxSz)); // front lower left - 6\n        qVerts.add(new Point3d(-skyBoxSz, -skyBoxSz, skyBoxSz)); // back lower left - 2\n        // Right (Left after rotation)\n        qVerts.add(new Point3d(skyBoxSz, skyBoxSz, skyBoxSz)); // back upper right - 1\n        qVerts.add(new Point3d(skyBoxSz, skyBoxSz, -skyBoxSz)); // front upper right - 5\n        qVerts.add(new Point3d(skyBoxSz, -skyBoxSz, skyBoxSz)); // back lower right - 3\n        qVerts.add(new Point3d(skyBoxSz, skyBoxSz, -skyBoxSz)); // front upper right - 5\n        qVerts.add(new Point3d(skyBoxSz, -skyBoxSz, -skyBoxSz)); // front lower right - 7\n        qVerts.add(new Point3d(skyBoxSz, -skyBoxSz, skyBoxSz)); // back lower right - 3\n        this.vertices = qVerts.toTypedArray();\n        this.vertexParams = qVerts.params;\n    }\n    createParams() {\n        return SkyBoxGeometryParams.create(this.vertices, this.vertexParams);\n    }\n}\n/** Parameters used to construct an SkyBox\n * @internal\n */\nexport class SkyBoxGeometryParams {\n    constructor(positions) {\n        this.buffers = BuffersContainer.create();\n        const attrPos = AttributeMap.findAttribute(\"a_pos\", undefined, false);\n        assert(attrPos !== undefined);\n        this.buffers.addBuffer(positions, [BufferParameters.create(attrPos.location, 3, GL.DataType.UnsignedShort, false, 0, 0, false)]);\n        this.positions = positions;\n    }\n    static create(positions, qparams) {\n        const posBuf = QBufferHandle3d.create(qparams, positions);\n        if (undefined === posBuf)\n            return undefined;\n        return new SkyBoxGeometryParams(posBuf);\n    }\n    get isDisposed() { return this.buffers.isDisposed && this.positions.isDisposed; }\n    dispose() {\n        dispose(this.buffers);\n        dispose(this.positions);\n    }\n}\n/** @internal */\n(function (SkyBoxQuads) {\n    let skyBoxQuads;\n    function getInstance() {\n        if (undefined === skyBoxQuads)\n            skyBoxQuads = new SkyBoxQuads();\n        return skyBoxQuads;\n    }\n    SkyBoxQuads.getInstance = getInstance;\n})(SkyBoxQuads || (SkyBoxQuads = {}));\n/** Geometry used for view-space rendering techniques.\n * @internal\n */\nexport class SkyBoxQuadsGeometry extends CachedGeometry {\n    constructor(ndxGeomParams, texture) {\n        super();\n        this.cube = texture;\n        this._techniqueId = 23 /* TechniqueId.SkyBox */;\n        this._params = ndxGeomParams;\n    }\n    static create(texture) {\n        const sbxGeomParams = SkyBoxQuads.getInstance().createParams();\n        return undefined !== sbxGeomParams ? new SkyBoxQuadsGeometry(sbxGeomParams, texture) : undefined;\n    }\n    collectStatistics(_stats) {\n        // Not interested in tracking this.\n    }\n    get techniqueId() { return this._techniqueId; }\n    getPass() { return \"skybox\"; }\n    get renderOrder() { return 3 /* RenderOrder.UnlitSurface */; }\n    draw() {\n        this._params.buffers.bind();\n        System.instance.context.drawArrays(GL.PrimitiveType.Triangles, 0, 36);\n        this._params.buffers.unbind();\n    }\n    get qOrigin() { return this._params.positions.origin; }\n    get qScale() { return this._params.positions.scale; }\n    get isDisposed() { return this._params.isDisposed; }\n    dispose() {\n        dispose(this._params);\n    }\n    _wantWoWReversal(_target) { return false; }\n}\n/** A quad with its corners mapped to the dimensions as the viewport, used for special rendering techniques.\n * @internal\n */\nclass ViewportQuad {\n    constructor() {\n        this.indices = new Uint32Array(6);\n        const pt = new Point3d(-1, -1, 0);\n        const vertices = new QPoint3dList(QParams3d.fromNormalizedRange());\n        vertices.add(pt);\n        pt.x = 1;\n        vertices.add(pt);\n        pt.y = 1;\n        vertices.add(pt);\n        pt.x = -1;\n        vertices.add(pt);\n        this.vertices = vertices.toTypedArray();\n        this.vertexParams = vertices.params;\n        this.indices[0] = 0;\n        this.indices[1] = 1;\n        this.indices[2] = 2;\n        this.indices[3] = 0;\n        this.indices[4] = 2;\n        this.indices[5] = 3;\n    }\n    createParams() {\n        return IndexedGeometryParams.create(this.vertices, this.vertexParams, this.indices);\n    }\n}\n/** @internal */\n(function (ViewportQuad) {\n    let viewportQuad;\n    function getInstance() {\n        if (undefined === viewportQuad)\n            viewportQuad = new ViewportQuad();\n        return viewportQuad;\n    }\n    ViewportQuad.getInstance = getInstance;\n})(ViewportQuad || (ViewportQuad = {}));\n/** Geometry used for view-space rendering techniques.\n * @internal\n */\nexport class ViewportQuadGeometry extends IndexedGeometry {\n    constructor(params, techniqueId) {\n        super(params);\n        this._techniqueId = techniqueId;\n    }\n    static create(techniqueId) {\n        const params = ViewportQuad.getInstance().createParams();\n        return undefined !== params ? new this(params, techniqueId) : undefined;\n    }\n    get techniqueId() { return this._techniqueId; }\n    getPass() { return \"opaque\"; }\n    get renderOrder() { return 3 /* RenderOrder.UnlitSurface */; }\n    collectStatistics(_stats) {\n        // NB: These don't really count...\n    }\n}\n/** Geometry used for view-space rendering techniques which involve sampling one or more textures.\n * @internal\n */\nexport class TexturedViewportQuadGeometry extends ViewportQuadGeometry {\n    constructor(params, techniqueId, textures) {\n        super(params, techniqueId);\n        this._textures = textures;\n        // TypeScript compiler will happily accept TextureHandle (or any other type) in place of WebGLTexture.\n        // There is no such 'type' as WebGLTexture at run-time.\n        assert(this._textures.every((tx) => !(tx instanceof TextureHandle)));\n    }\n    static createTexturedViewportQuadGeometry(techniqueId, textures) {\n        const params = ViewportQuad.getInstance().createParams();\n        if (undefined === params)\n            return undefined;\n        return new this(params, techniqueId, textures);\n    }\n}\n/** Geometry used for rendering default gradient-style or single texture spherical skybox.\n * @internal\n */\nexport class SkySphereViewportQuadGeometry extends ViewportQuadGeometry {\n    initWorldPos(target) {\n        if (this._isWorldPosSet)\n            return;\n        this._isWorldPosSet = true;\n        this._setPointsFromFrustum(target);\n        this._worldPosBuff.bindData(this.worldPos, GL.Buffer.Usage.StreamDraw);\n        const attrWorldPos = AttributeMap.findAttribute(\"a_worldPos\", 24 /* TechniqueId.SkySphereGradient */, false);\n        assert(attrWorldPos !== undefined);\n        this._params.buffers.addBuffer(this._worldPosBuff, [BufferParameters.create(attrWorldPos.location, 3, GL.DataType.Float, false, 0, 0, false)]);\n    }\n    _setPointsFromFrustum(target) {\n        const frustum = target.planFrustum;\n        const wp = this.worldPos;\n        const lb = frustum.getCorner(Npc.LeftBottomRear).interpolate(0.5, frustum.getCorner(Npc.LeftBottomFront), scratchPoint3a);\n        const rb = frustum.getCorner(Npc.RightBottomRear).interpolate(0.5, frustum.getCorner(Npc.RightBottomFront), scratchPoint3b);\n        const rt = frustum.getCorner(Npc.RightTopRear).interpolate(0.5, frustum.getCorner(Npc.RightTopFront), scratchPoint3c);\n        if (!target.plan.backgroundMapOn || !target.plan.isGlobeMode3D) {\n            wp[0] = lb.x;\n            wp[1] = lb.y;\n            wp[2] = lb.z;\n            wp[3] = rb.x;\n            wp[4] = rb.y;\n            wp[5] = rb.z;\n            wp[6] = rt.x;\n            wp[7] = rt.y;\n            wp[8] = rt.z;\n            const lt = frustum.getCorner(Npc.LeftTopRear).interpolate(0.5, frustum.getCorner(Npc.LeftTopFront), scratchPoint3d);\n            wp[9] = lt.x;\n            wp[10] = lt.y;\n            wp[11] = lt.z;\n        }\n        else {\n            // Need to fake a different frustum to orient the 4 corners properly.\n            // First find true frustum center & size.\n            const fCenter = lb.interpolate(0.5, rt, scratchPoint3d);\n            const upScreen = Vector3d.createStartEnd(rb, rt, scratchVec3a);\n            let rightScreen = Vector3d.createStartEnd(lb, rb, scratchVec3b);\n            const halfWidth = upScreen.magnitude() * 0.5;\n            const halfHeight = rightScreen.magnitude() * 0.5;\n            // Find the projection of the globe up onto the frustum plane.\n            upScreen.normalizeInPlace();\n            rightScreen.normalizeInPlace();\n            const projUp = target.plan.upVector.dotProduct(upScreen);\n            const projRt = target.plan.upVector.dotProduct(rightScreen);\n            // Find camera position (create one for ortho).\n            let camPos;\n            if (2 /* FrustumUniformType.Perspective */ === target.uniforms.frustum.type) {\n                const farLowerLeft = frustum.getCorner(Npc.LeftBottomRear);\n                const nearLowerLeft = frustum.getCorner(Npc.LeftBottomFront);\n                const scale = 1.0 / (1.0 - target.planFraction);\n                const zVec = Vector3d.createStartEnd(farLowerLeft, nearLowerLeft, scratchVec3c);\n                camPos = fromSumOf(farLowerLeft, zVec, scale, scratchPoint3a);\n            }\n            else {\n                const delta = Vector3d.createStartEnd(frustum.getCorner(Npc.LeftBottomRear), frustum.getCorner(Npc.LeftBottomFront), scratchVec3c);\n                const pseudoCameraHalfAngle = 22.5;\n                const diagonal = frustum.getCorner(Npc.LeftBottomRear).distance(frustum.getCorner(Npc.RightTopRear));\n                const focalLength = diagonal / (2 * Math.atan(pseudoCameraHalfAngle * Angle.radiansPerDegree));\n                let zScale = focalLength / delta.magnitude();\n                if (zScale < 1.000001)\n                    zScale = 1.000001; // prevent worldEye front being on or inside the frustum front plane\n                camPos = Point3d.createAdd3Scaled(frustum.getCorner(Npc.LeftBottomRear), .5, frustum.getCorner(Npc.RightTopRear), .5, delta, zScale, scratchPoint3a);\n            }\n            // Compute the distance from the camera to the frustum center.\n            const camDist = camPos.distance(fCenter);\n            // Now use a fixed camera direction and compute a new frustum center.\n            const camDir = Vector3d.create(0.0, 1.0, 0.0, scratchVec3c);\n            fCenter.setFromPoint3d(camPos);\n            fCenter.addScaledInPlace(camDir, camDist);\n            // Create an up vector that mimics the projection of the globl up onto the real frustum.\n            upScreen.set(projRt, 0.0, projUp);\n            upScreen.normalizeInPlace();\n            // Compute a new right vector and then compute the 4 points for the sky.\n            rightScreen = upScreen.crossProduct(camDir, scratchVec3b);\n            upScreen.scaleInPlace(halfHeight);\n            rightScreen.scaleInPlace(halfWidth);\n            wp[0] = fCenter.x - rightScreen.x - upScreen.x; // left bottom\n            wp[1] = fCenter.y - rightScreen.y - upScreen.y;\n            wp[2] = fCenter.z - rightScreen.z - upScreen.z;\n            wp[3] = fCenter.x + rightScreen.x - upScreen.x; // right bottom\n            wp[4] = fCenter.y + rightScreen.y - upScreen.y;\n            wp[5] = fCenter.z + rightScreen.z - upScreen.z;\n            wp[6] = fCenter.x + rightScreen.x + upScreen.x; // right top\n            wp[7] = fCenter.y + rightScreen.y + upScreen.y;\n            wp[8] = fCenter.z + rightScreen.z + upScreen.z;\n            wp[9] = fCenter.x - rightScreen.x + upScreen.x; // left top\n            wp[10] = fCenter.y - rightScreen.y + upScreen.y;\n            wp[11] = fCenter.z - rightScreen.z + upScreen.z;\n        }\n    }\n    constructor(params, skybox, techniqueId) {\n        super(params, techniqueId);\n        this._isWorldPosSet = false;\n        this.worldPos = new Float32Array(4 * 3);\n        this._worldPosBuff = new BufferHandle(GL.Buffer.Target.ArrayBuffer);\n        this.typeAndExponents = new Float32Array(3);\n        this.zenithColor = new Float32Array(3);\n        this.skyColor = new Float32Array(3);\n        this.groundColor = new Float32Array(3);\n        this.nadirColor = new Float32Array(3);\n        this.zOffset = skybox.zOffset;\n        this.rotation = \"sphere\" === skybox.type ? skybox.rotation : 0;\n        if (skybox.type === \"sphere\") {\n            this.skyTexture = skybox.texture;\n            this.typeAndExponents[0] = 0.0;\n            this.typeAndExponents[1] = 1.0;\n            this.typeAndExponents[2] = 1.0;\n            this.zenithColor[0] = 0.0;\n            this.zenithColor[1] = 0.0;\n            this.zenithColor[2] = 0.0;\n            this.nadirColor[0] = 0.0;\n            this.nadirColor[1] = 0.0;\n            this.nadirColor[2] = 0.0;\n            this.skyColor[0] = 0.0;\n            this.skyColor[1] = 0.0;\n            this.skyColor[2] = 0.0;\n            this.groundColor[0] = 0.0;\n            this.groundColor[1] = 0.0;\n            this.groundColor[2] = 0.0;\n        }\n        else {\n            const gradient = skybox.gradient;\n            this.zenithColor[0] = gradient.zenithColor.colors.r / 255.0;\n            this.zenithColor[1] = gradient.zenithColor.colors.g / 255.0;\n            this.zenithColor[2] = gradient.zenithColor.colors.b / 255.0;\n            this.nadirColor[0] = gradient.nadirColor.colors.r / 255.0;\n            this.nadirColor[1] = gradient.nadirColor.colors.g / 255.0;\n            this.nadirColor[2] = gradient.nadirColor.colors.b / 255.0;\n            if (gradient.twoColor) {\n                this.typeAndExponents[0] = -1.0;\n                this.typeAndExponents[1] = 4.0;\n                this.typeAndExponents[2] = 4.0;\n                this.skyColor[0] = 0.0;\n                this.skyColor[1] = 0.0;\n                this.skyColor[2] = 0.0;\n                this.groundColor[0] = 0.0;\n                this.groundColor[1] = 0.0;\n                this.groundColor[2] = 0.0;\n            }\n            else {\n                this.typeAndExponents[0] = 1.0;\n                this.typeAndExponents[1] = gradient.skyExponent;\n                this.typeAndExponents[2] = gradient.groundExponent;\n                this.skyColor[0] = gradient.skyColor.colors.r / 255.0;\n                this.skyColor[1] = gradient.skyColor.colors.g / 255.0;\n                this.skyColor[2] = gradient.skyColor.colors.b / 255.0;\n                this.groundColor[0] = gradient.groundColor.colors.r / 255.0;\n                this.groundColor[1] = gradient.groundColor.colors.g / 255.0;\n                this.groundColor[2] = gradient.groundColor.colors.b / 255.0;\n            }\n        }\n    }\n    static createGeometry(skybox) {\n        const params = ViewportQuad.getInstance().createParams();\n        if (undefined === params)\n            return undefined;\n        const technique = \"sphere\" === skybox.type ? 25 /* TechniqueId.SkySphereTexture */ : 24 /* TechniqueId.SkySphereGradient */;\n        return new SkySphereViewportQuadGeometry(params, skybox, technique);\n    }\n    get isDisposed() { return super.isDisposed && this._worldPosBuff.isDisposed; }\n    dispose() {\n        super.dispose();\n        dispose(this._worldPosBuff);\n    }\n}\n/** Geometry used when rendering ambient occlusion information to an output texture\n * @internal\n */\nexport class AmbientOcclusionGeometry extends TexturedViewportQuadGeometry {\n    static createGeometry(depthAndOrder, depth) {\n        const params = ViewportQuad.getInstance().createParams();\n        if (undefined === params) {\n            return undefined;\n        }\n        // Will derive positions and normals from depthAndOrder.\n        return new AmbientOcclusionGeometry(params, [depth, depthAndOrder]);\n    }\n    get depthAndOrder() { return this._textures[1]; }\n    get depth() { return this._textures[0]; }\n    get noise() { return System.instance.noiseTexture.getHandle(); }\n    constructor(params, textures) {\n        super(params, 26 /* TechniqueId.AmbientOcclusion */, textures);\n    }\n}\n/** @internal */\nexport var BlurType;\n(function (BlurType) {\n    BlurType[BlurType[\"NoTest\"] = 0] = \"NoTest\";\n    BlurType[BlurType[\"TestOrder\"] = 1] = \"TestOrder\";\n})(BlurType || (BlurType = {}));\n/** @internal */\nexport class BlurGeometry extends TexturedViewportQuadGeometry {\n    static createGeometry(texToBlur, depthAndOrder, depthAndOrderHidden, blurDir, blurType) {\n        const params = ViewportQuad.getInstance().createParams();\n        if (undefined === params) {\n            return undefined;\n        }\n        if (undefined === depthAndOrderHidden || BlurType.NoTest === blurType)\n            return new BlurGeometry(params, [texToBlur, depthAndOrder], blurDir, blurType);\n        else\n            return new BlurGeometry(params, [texToBlur, depthAndOrder, depthAndOrderHidden], blurDir, blurType);\n    }\n    get textureToBlur() { return this._textures[0]; }\n    get depthAndOrder() { return this._textures[1]; }\n    get depthAndOrderHidden() { return this._textures[2]; }\n    constructor(params, textures, blurDir, blurType) {\n        super(params, BlurType.NoTest === blurType ? 27 /* TechniqueId.Blur */ : 28 /* TechniqueId.BlurTestOrder */, textures);\n        this.blurDir = blurDir;\n    }\n}\n/** @internal */\nexport class EDLCalcBasicGeometry extends TexturedViewportQuadGeometry {\n    static createGeometry(colorBuffer, depthBuffer, width, height) {\n        const params = ViewportQuad.getInstance().createParams();\n        if (undefined === params)\n            return undefined;\n        return new EDLCalcBasicGeometry(params, [colorBuffer, depthBuffer], width, height);\n    }\n    get colorTexture() { return this._textures[0]; }\n    get depthTexture() { return this._textures[1]; }\n    constructor(params, textures, width, height) {\n        super(params, 34 /* TechniqueId.EDLCalcBasic */, textures);\n        this.texInfo = new Float32Array(3);\n        this.texInfo[0] = 1.0 / width;\n        this.texInfo[1] = 1.0 / height;\n        this.texInfo[2] = 1.0;\n    }\n}\n/** @internal */\nexport class EDLCalcFullGeometry extends TexturedViewportQuadGeometry {\n    static createGeometry(colorBuffer, depthBuffer, scale, width, height) {\n        const params = ViewportQuad.getInstance().createParams();\n        if (undefined === params)\n            return undefined;\n        return new EDLCalcFullGeometry(params, [colorBuffer, depthBuffer], scale, width, height);\n    }\n    get colorTexture() { return this._textures[0]; }\n    get depthTexture() { return this._textures[1]; }\n    constructor(params, textures, scale, width, height) {\n        super(params, 35 /* TechniqueId.EDLCalcFull */, textures);\n        this.texInfo = new Float32Array(3);\n        this.texInfo[0] = 1.0 / width;\n        this.texInfo[1] = 1.0 / height;\n        this.texInfo[2] = scale;\n    }\n}\n/** @internal */\nexport class EDLFilterGeometry extends TexturedViewportQuadGeometry {\n    static createGeometry(colorBuffer, depthBuffer, scale, width, height) {\n        const params = ViewportQuad.getInstance().createParams();\n        if (undefined === params)\n            return undefined;\n        return new EDLFilterGeometry(params, [colorBuffer, depthBuffer], scale, width, height);\n    }\n    get colorTexture() { return this._textures[0]; }\n    get depthTexture() { return this._textures[1]; }\n    constructor(params, textures, scale, width, height) {\n        super(params, 36 /* TechniqueId.EDLFilter */, textures);\n        this.texInfo = new Float32Array(3);\n        this.texInfo[0] = 1.0 / width;\n        this.texInfo[1] = 1.0 / height;\n        this.texInfo[2] = scale;\n    }\n}\n/** @internal */\nexport class EDLMixGeometry extends TexturedViewportQuadGeometry {\n    static createGeometry(colorTexture1, colorTexture2, colorTexture4) {\n        const params = ViewportQuad.getInstance().createParams();\n        if (undefined === params)\n            return undefined;\n        return new EDLMixGeometry(params, [colorTexture1, colorTexture2, colorTexture4]);\n    }\n    get colorTexture1() { return this._textures[0]; }\n    get colorTexture2() { return this._textures[1]; }\n    get colorTexture4() { return this._textures[2]; }\n    constructor(params, textures) {\n        super(params, 37 /* TechniqueId.EDLMix */, textures);\n    }\n}\n/** @internal */\nexport class EVSMGeometry extends TexturedViewportQuadGeometry {\n    static createGeometry(depthBuffer, width, height) {\n        const params = ViewportQuad.getInstance().createParams();\n        if (undefined === params)\n            return undefined;\n        return new EVSMGeometry(params, [depthBuffer], width, height);\n    }\n    get depthTexture() { return this._textures[0]; }\n    constructor(params, textures, width, height) {\n        super(params, 22 /* TechniqueId.EVSMFromDepth */, textures);\n        this.stepSize = new Float32Array(2);\n        this.stepSize[0] = 1.0 / width;\n        this.stepSize[1] = 1.0 / height;\n    }\n}\n/** Geometry used during the 'composite' pass to apply transparency and/or hilite effects.\n * @internal\n */\nexport class CompositeGeometry extends TexturedViewportQuadGeometry {\n    static createGeometry(opaque, accum, reveal, hilite) {\n        const params = ViewportQuad.getInstance().createParams();\n        if (undefined === params)\n            return undefined;\n        const textures = [opaque, accum, reveal, hilite];\n        return new CompositeGeometry(params, textures);\n    }\n    get opaque() { return this._textures[0]; }\n    get accum() { return this._textures[1]; }\n    get reveal() { return this._textures[2]; }\n    get hilite() { return this._textures[3]; }\n    get occlusion() {\n        return this._textures.length > 4 ? this._textures[4] : undefined;\n    }\n    set occlusion(occlusion) {\n        assert((undefined === occlusion) === (undefined !== this.occlusion));\n        if (undefined !== occlusion)\n            this._textures[4] = occlusion;\n        else\n            this._textures.length = 4;\n    }\n    // Invoked each frame to determine the appropriate Technique to use.\n    update(flags) { this._techniqueId = this.determineTechnique(flags); }\n    determineTechnique(flags) {\n        return computeCompositeTechniqueId(flags);\n    }\n    constructor(params, textures) {\n        super(params, 9 /* TechniqueId.CompositeHilite */, textures);\n        assert(4 <= this._textures.length);\n    }\n}\n/** Geometry used to ping-pong the pick buffer data in between opaque passes.\n * @internal\n */\nexport class CopyPickBufferGeometry extends TexturedViewportQuadGeometry {\n    static createGeometry(featureId, depthAndOrder) {\n        const params = ViewportQuad.getInstance().createParams();\n        if (undefined !== params) {\n            return new CopyPickBufferGeometry(params, [featureId, depthAndOrder]);\n        }\n        else {\n            return undefined;\n        }\n    }\n    get featureId() { return this._textures[0]; }\n    get depthAndOrder() { return this._textures[1]; }\n    constructor(params, textures) {\n        super(params, 17 /* TechniqueId.CopyPickBuffers */, textures);\n    }\n}\nexport class CombineTexturesGeometry extends TexturedViewportQuadGeometry {\n    static createGeometry(texture0, texture1) {\n        const params = ViewportQuad.getInstance().createParams();\n        if (undefined !== params) {\n            return new CombineTexturesGeometry(params, [texture0, texture1]);\n        }\n        else {\n            return undefined;\n        }\n    }\n    get texture0() { return this._textures[0]; }\n    get texture1() { return this._textures[1]; }\n    constructor(params, textures) {\n        super(params, 29 /* TechniqueId.CombineTextures */, textures);\n    }\n}\nexport class Combine3TexturesGeometry extends TexturedViewportQuadGeometry {\n    static createGeometry(texture0, texture1, texture2) {\n        const params = ViewportQuad.getInstance().createParams();\n        if (undefined !== params) {\n            return new Combine3TexturesGeometry(params, [texture0, texture1, texture2]);\n        }\n        else {\n            return undefined;\n        }\n    }\n    get texture0() { return this._textures[0]; }\n    get texture1() { return this._textures[1]; }\n    get texture2() { return this._textures[2]; }\n    constructor(params, textures) {\n        super(params, 30 /* TechniqueId.Combine3Textures */, textures);\n    }\n}\n/** @internal */\nexport class SingleTexturedViewportQuadGeometry extends TexturedViewportQuadGeometry {\n    static createGeometry(texture, techId) {\n        const params = ViewportQuad.getInstance().createParams();\n        if (undefined === params) {\n            return undefined;\n        }\n        return new SingleTexturedViewportQuadGeometry(params, texture, techId);\n    }\n    get texture() { return this._textures[0]; }\n    set texture(texture) { this._textures[0] = texture; }\n    constructor(params, texture, techId) {\n        super(params, techId, [texture]);\n    }\n}\n/** @internal */\nexport var BoundaryType;\n(function (BoundaryType) {\n    BoundaryType[BoundaryType[\"Outside\"] = 0] = \"Outside\";\n    BoundaryType[BoundaryType[\"Inside\"] = 1] = \"Inside\";\n    BoundaryType[BoundaryType[\"Selected\"] = 2] = \"Selected\";\n})(BoundaryType || (BoundaryType = {}));\n/** @internal */\nexport class VolumeClassifierGeometry extends SingleTexturedViewportQuadGeometry {\n    static createVCGeometry(texture) {\n        const params = ViewportQuad.getInstance().createParams();\n        if (undefined === params)\n            return undefined;\n        return new VolumeClassifierGeometry(params, texture);\n    }\n    constructor(params, texture) {\n        super(params, texture, 32 /* TechniqueId.VolClassSetBlend */);\n        this.boundaryType = BoundaryType.Inside;\n    }\n}\n/** A geometric primitive which renders gl points using gl.drawArrays() with one vertex buffer.\n * @internal\n */\nexport class ScreenPointsGeometry extends CachedGeometry {\n    constructor(vertices, zTexture) {\n        super();\n        this.zTexture = zTexture;\n        this._numPoints = vertices.length;\n        this._positions = QBufferHandle2d.create(vertices.params, vertices.toTypedArray());\n        this._origin = new Float32Array(3);\n        this._origin[0] = this._positions.params[0];\n        this._origin[1] = this._positions.params[1];\n        this._origin[2] = 0.0;\n        this._scale = new Float32Array(3);\n        this._scale[0] = this._positions.params[2];\n        this._scale[1] = this._positions.params[3];\n        this._scale[2] = this._positions.params[3]; // just copy the scale from y\n        this.buffers = BuffersContainer.create();\n        const attrPos = AttributeMap.findAttribute(\"a_pos\", 31 /* TechniqueId.VolClassCopyZ */, false);\n        assert(attrPos !== undefined);\n        this.buffers.addBuffer(this._positions, [BufferParameters.create(attrPos.location, 2, GL.DataType.UnsignedShort, false, 0, 0, false)]);\n    }\n    static createGeometry(width, height, depth) {\n        const pixWidth = 2.0 / width;\n        const pixHeight = 2.0 / height;\n        const startX = pixWidth * 0.5 - 1.0;\n        const startY = pixHeight * 0.5 - 1.0;\n        const pt = new Point2d(startX, startY);\n        const vertices = new QPoint2dList(QParams2d.fromNormalizedRange());\n        for (let y = 0; y < height; ++y) {\n            pt.x = startX;\n            for (let x = 0; x < width; ++x) {\n                vertices.add(pt);\n                pt.x += pixWidth;\n            }\n            pt.y += pixHeight;\n        }\n        return new ScreenPointsGeometry(vertices, depth);\n    }\n    draw() {\n        this.buffers.bind();\n        System.instance.context.drawArrays(GL.PrimitiveType.Points, 0, this._numPoints);\n        this.buffers.unbind();\n    }\n    get isDisposed() { return this.buffers.isDisposed && this._positions.isDisposed; }\n    dispose() {\n        dispose(this.buffers);\n        dispose(this._positions);\n    }\n    collectStatistics(stats) {\n        stats.addBuffer(RenderMemory.BufferType.PointStrings, this._positions.bytesUsed);\n    }\n    _wantWoWReversal(_target) { return false; }\n    get techniqueId() { return 31 /* TechniqueId.VolClassCopyZ */; }\n    getPass() { return \"classification\"; }\n    get renderOrder() { return 0 /* RenderOrder.None */; }\n    get qOrigin() { return this._origin; }\n    get qScale() { return this._scale; }\n}\n/** @internal */\nexport class PolylineBuffers {\n    constructor(indices, prevIndices, nextIndicesAndParams) {\n        this.buffers = BuffersContainer.create();\n        const attrPos = AttributeMap.findAttribute(\"a_pos\", 1 /* TechniqueId.Polyline */, false);\n        const attrPrevIndex = AttributeMap.findAttribute(\"a_prevIndex\", 1 /* TechniqueId.Polyline */, false);\n        const attrNextIndex = AttributeMap.findAttribute(\"a_nextIndex\", 1 /* TechniqueId.Polyline */, false);\n        const attrParam = AttributeMap.findAttribute(\"a_param\", 1 /* TechniqueId.Polyline */, false);\n        assert(attrPos !== undefined);\n        assert(attrPrevIndex !== undefined);\n        assert(attrNextIndex !== undefined);\n        assert(attrParam !== undefined);\n        this.buffers.addBuffer(indices, [BufferParameters.create(attrPos.location, 3, GL.DataType.UnsignedByte, false, 0, 0, false)]);\n        this.buffers.addBuffer(prevIndices, [BufferParameters.create(attrPrevIndex.location, 3, GL.DataType.UnsignedByte, false, 0, 0, false)]);\n        this.buffers.addBuffer(nextIndicesAndParams, [\n            BufferParameters.create(attrNextIndex.location, 3, GL.DataType.UnsignedByte, false, 4, 0, false),\n            BufferParameters.create(attrParam.location, 1, GL.DataType.UnsignedByte, false, 4, 3, false),\n        ]);\n        this.indices = indices;\n        this.prevIndices = prevIndices;\n        this.nextIndicesAndParams = nextIndicesAndParams;\n    }\n    static create(polyline) {\n        const indices = BufferHandle.createArrayBuffer(polyline.indices.data);\n        const prev = BufferHandle.createArrayBuffer(polyline.prevIndices.data);\n        const next = BufferHandle.createArrayBuffer(polyline.nextIndicesAndParams);\n        return undefined !== indices && undefined !== prev && undefined !== next ? new PolylineBuffers(indices, prev, next) : undefined;\n    }\n    collectStatistics(stats, type) {\n        stats.addBuffer(type, this.indices.bytesUsed + this.prevIndices.bytesUsed + this.nextIndicesAndParams.bytesUsed);\n    }\n    get isDisposed() {\n        return this.buffers.isDisposed\n            && this.indices.isDisposed\n            && this.prevIndices.isDisposed\n            && this.nextIndicesAndParams.isDisposed;\n    }\n    dispose() {\n        dispose(this.buffers);\n        dispose(this.indices);\n        dispose(this.prevIndices);\n        dispose(this.nextIndicesAndParams);\n    }\n}\n//# sourceMappingURL=CachedGeometry.js.map",
      "start": 1693508121070,
      "end": 1693508121337,
      "sourcemaps": null
    }
  ]
}
