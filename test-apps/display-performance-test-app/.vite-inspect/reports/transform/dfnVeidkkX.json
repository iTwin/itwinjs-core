{
  "resolvedId": "D:/hub2023A/itwinjs-core/core/frontend/lib/esm/tile/GltfReader.js",
  "transforms": [
    {
      "name": "vite:load-fallback",
      "result": "/*---------------------------------------------------------------------------------------------\n* Copyright (c) Bentley Systems, Incorporated. All rights reserved.\n* See LICENSE.md in the project root for license terms and full copyright notice.\n*--------------------------------------------------------------------------------------------*/\n/** @packageDocumentation\n * @module Tiles\n */\nimport { assert, ByteStream, compareBooleans, compareNumbers, compareStrings, Dictionary, JsonUtils, Logger, utf8ToString, } from \"@itwin/core-bentley\";\nimport { Angle, IndexedPolyface, Matrix3d, Point2d, Point3d, Point4d, Range2d, Range3d, Transform, Vector3d, } from \"@itwin/core-geometry\";\nimport { BatchType, ColorDef, Feature, FeatureIndex, FeatureIndexType, FeatureTable, FillFlags, GlbHeader, ImageSource, LinePixels, MeshEdge, MeshEdges, MeshPolyline, OctEncodedNormal, PackedFeatureTable, QParams2d, QParams3d, QPoint2dList, QPoint3dList, Quantization, RenderTexture, TextureMapping, TextureTransparency, TileFormat, TileReadStatus, } from \"@itwin/core-common\";\nimport { IModelApp } from \"../IModelApp\";\nimport { GraphicBranch } from \"../render/GraphicBranch\";\nimport { RealityMeshParams } from \"../render/RealityMeshParams\";\nimport { Mesh } from \"../render/primitives/mesh/MeshPrimitives\";\nimport { Triangle } from \"../render/primitives/Primitives\";\nimport { DisplayParams } from \"../common/render/primitives/DisplayParams\";\nimport { FrontendLoggerCategory } from \"../common/FrontendLoggerCategory\";\nimport { getImageSourceFormatForMimeType, imageBitmapFromImageSource, imageElementFromImageSource, tryImageElementFromUrl } from \"../common/ImageUtil\";\nimport { MeshPrimitiveType } from \"../common/render/primitives/MeshPrimitive\";\nimport { getGltfNodeMeshIds, GltfDataType, gltfDictionaryIterator, GltfMeshMode, GltfTechniqueState, GltfWrapMode, isGltf1Material, traverseGltfNodes, } from \"../common/gltf/GltfSchema\";\n/**\n * A chunk of binary data exposed as a typed array.\n * The count member indicates how many elements exist. This may be less than this.buffer.length due to padding added to the\n * binary stream to ensure correct alignment.\n * @internal\n */\nexport class GltfBufferData {\n    constructor(buffer, count) {\n        this.buffer = buffer;\n        this.count = count;\n    }\n    /**\n     * Create a GltfBufferData of the desired type. The actual type may differ from the desired type - for example, small 32-bit integers\n     * may be represented as 8-bit or 16-bit integers instead.\n     * If the actual data type is not convertible to the desired type, this function returns undefined.\n     */\n    static create(bytes, actualType, expectedType, count) {\n        if (expectedType !== actualType) {\n            // Some data is stored in smaller data types to save space if no values exceed the maximum of the smaller type.\n            switch (expectedType) {\n                case GltfDataType.Float:\n                case GltfDataType.UnsignedByte:\n                    return undefined;\n                case GltfDataType.UnsignedShort:\n                    if (GltfDataType.UnsignedByte !== actualType)\n                        return undefined;\n                    break;\n                case GltfDataType.UInt32:\n                    if (GltfDataType.UnsignedByte !== actualType && GltfDataType.UnsignedShort !== actualType)\n                        return undefined;\n                    break;\n            }\n        }\n        const data = this.createDataBuffer(bytes, actualType);\n        return undefined !== data ? new GltfBufferData(data, count) : undefined;\n    }\n    static createDataBuffer(bytes, actualType) {\n        // NB: Endianness of typed array data is determined by the 'platform byte order'. Actual data is always little-endian.\n        // We are assuming little-endian platform. If we find a big-endian platform, we'll need to use a DataView instead.\n        switch (actualType) {\n            case GltfDataType.UnsignedByte:\n                return bytes;\n            case GltfDataType.UnsignedShort:\n                return new Uint16Array(bytes.buffer, bytes.byteOffset, bytes.byteLength / 2);\n            case GltfDataType.UInt32:\n                return new Uint32Array(bytes.buffer, bytes.byteOffset, bytes.byteLength / 4);\n            case GltfDataType.Float:\n                return new Float32Array(bytes.buffer, bytes.byteOffset, bytes.byteLength / 4);\n            default:\n                return undefined;\n        }\n    }\n}\n/**\n * A view of a chunk of glTF binary data containing an array of elements of a specific data type.\n * The count member indicates how many elements exist; this may be smaller than this.data.length.\n * The count member may also indicate the number of elements of a type containing more than one value of the\n * underlying type. For example, a buffer of 4 32-bit floating point 'vec2' elements will have a count of 4,\n * but its data member will contain 8 32-bit floating point values (2 per vec2).\n * The accessor member may contain additional JSON data specific to a particular buffer.\n * @internal\n */\nclass GltfBufferView {\n    get byteLength() { return this.data.length; }\n    constructor(data, count, type, accessor, stride) {\n        this.data = data;\n        this.count = count;\n        this.type = type;\n        this.accessor = accessor;\n        this.stride = stride;\n    }\n    toBufferData(desiredType) {\n        return GltfBufferData.create(this.data, this.type, desiredType, this.count);\n    }\n}\n/** Data required for creating a [[GltfReader]] capable of deserializing [glTF](https://www.khronos.org/gltf/).\n * @internal\n */\nexport class GltfReaderProps {\n    constructor(glTF, version, yAxisUp, binaryData, baseUrl) {\n        this.version = version;\n        this.glTF = glTF;\n        this.binaryData = binaryData;\n        this.yAxisUp = yAxisUp;\n        this.baseUrl = baseUrl;\n    }\n    /** Attempt to construct a new GltfReaderProps from the binary data beginning at the supplied stream's current read position. */\n    static create(source, yAxisUp = false, baseUrl) {\n        let version;\n        let json;\n        let binaryData;\n        if (source instanceof Uint8Array) {\n            // It may be JSON - check for magic indicating glb.\n            const buffer = ByteStream.fromUint8Array(source);\n            if (TileFormat.Gltf !== buffer.readUint32()) {\n                try {\n                    const utf8Json = utf8ToString(source);\n                    if (!utf8Json)\n                        return undefined;\n                    json = JSON.parse(utf8Json);\n                    version = 2;\n                }\n                catch (_) {\n                    return undefined;\n                }\n            }\n            else {\n                buffer.reset();\n                const header = new GlbHeader(buffer);\n                if (!header.isValid)\n                    return undefined;\n                version = header.version;\n                if (header.binaryChunk)\n                    binaryData = new Uint8Array(source.buffer, source.byteOffset + header.binaryChunk.offset, header.binaryChunk.length);\n                try {\n                    const jsonBytes = new Uint8Array(source.buffer, source.byteOffset + header.jsonChunk.offset, header.jsonChunk.length);\n                    const jsonStr = utf8ToString(jsonBytes);\n                    if (undefined === jsonStr)\n                        return undefined;\n                    json = JSON.parse(jsonStr);\n                }\n                catch (_) {\n                    return undefined;\n                }\n            }\n        }\n        else {\n            version = 2; // ###TODO verify against source.asset?.version\n            json = source;\n        }\n        // asset is required in glTF 2, optional in glTF 1\n        const asset = JsonUtils.asObject(json.asset);\n        if (version === 2 && !asset)\n            return undefined;\n        const glTF = {\n            asset,\n            scene: JsonUtils.asString(json.scene),\n            extensions: JsonUtils.asObject(json.extensions),\n            extensionsUsed: JsonUtils.asArray(json.extensionsUsed),\n            extensionsRequired: JsonUtils.asArray(json.extensionsRequired),\n            accessors: JsonUtils.asObject(json.accessors),\n            buffers: JsonUtils.asObject(json.buffers),\n            bufferViews: JsonUtils.asObject(json.bufferViews),\n            images: JsonUtils.asObject(json.images),\n            materials: JsonUtils.asObject(json.materials),\n            meshes: JsonUtils.asObject(json.meshes),\n            nodes: JsonUtils.asObject(json.nodes),\n            samplers: JsonUtils.asObject(json.samplers),\n            scenes: JsonUtils.asObject(json.scenes),\n            textures: JsonUtils.asObject(json.textures),\n            techniques: JsonUtils.asObject(json.techniques),\n        };\n        return glTF.meshes ? new GltfReaderProps(glTF, version, yAxisUp, binaryData, baseUrl) : undefined;\n    }\n}\n/** The GltfMeshData contains the raw GLTF mesh data. If the data is suitable to create a [[RealityMesh]] directly, basically in the quantized format produced by\n  * ContextCapture, then a RealityMesh is created directly from this data. Otherwise, the mesh primitive is populated from the raw data and a MeshPrimitive\n  * is generated. The MeshPrimitve path is much less efficient but should be rarely used.\n  *\n  * @internal\n  */\nexport class GltfMeshData {\n    constructor(props) {\n        this.type = \"mesh\";\n        this.primitive = props;\n    }\n}\nconst emptyDict = {};\nfunction colorFromJson(values) {\n    return ColorDef.from(values[0] * 255, values[1] * 255, values[2] * 255, (1.0 - values[3]) * 255);\n}\nfunction colorFromMaterial(material, isTransparent) {\n    let color = ColorDef.white;\n    if (isGltf1Material(material)) {\n        if (material.values?.color && Array.isArray(material.values.color))\n            color = colorFromJson(material.values.color);\n    }\n    else if (material.extensions?.KHR_techniques_webgl?.values?.u_color) {\n        color = colorFromJson(material.extensions.KHR_techniques_webgl.values.u_color);\n    }\n    else if (material.pbrMetallicRoughness?.baseColorFactor) {\n        color = colorFromJson(material.pbrMetallicRoughness.baseColorFactor);\n    }\n    // SPEC: Opaque materials ignore any alpha channel.\n    if (!isTransparent)\n        color = color.withTransparency(0);\n    return color;\n}\nclass TransformStack {\n    constructor(transform) {\n        this._stack = [];\n        if (transform)\n            this._stack.push(transform);\n    }\n    get transform() {\n        return this._stack.length > 0 ? this._stack[this._stack.length - 1] : undefined;\n    }\n    get isEmpty() {\n        return 0 === this._stack.length;\n    }\n    push(node) {\n        let nodeTransform;\n        if (node.matrix) {\n            const origin = Point3d.create(node.matrix[12], node.matrix[13], node.matrix[14]);\n            const matrix = Matrix3d.createRowValues(node.matrix[0], node.matrix[4], node.matrix[8], node.matrix[1], node.matrix[5], node.matrix[9], node.matrix[2], node.matrix[6], node.matrix[10]);\n            nodeTransform = Transform.createOriginAndMatrix(origin, matrix);\n        }\n        else if (node.rotation || node.scale || node.translation) {\n            // SPEC: To compose the local transformation matrix, TRS properties MUST be converted to matrices and postmultiplied in the T * R * S order;\n            // first the scale is applied to the vertices, then the rotation, and then the translation.\n            const scale = Transform.createRefs(undefined, node.scale ? Matrix3d.createScale(node.scale[0], node.scale[1], node.scale[2]) : Matrix3d.identity);\n            const rot = Transform.createRefs(undefined, node.rotation ? Matrix3d.createFromQuaternion(Point4d.create(node.rotation[0], node.rotation[1], node.rotation[2], node.rotation[3])) : Matrix3d.identity);\n            rot.matrix.transposeInPlace(); // See comment on Matrix3d.createFromQuaternion\n            const trans = Transform.createTranslation(node.translation ? new Point3d(node.translation[0], node.translation[1], node.translation[2]) : Point3d.createZero());\n            nodeTransform = scale.multiplyTransformTransform(rot);\n            trans.multiplyTransformTransform(nodeTransform, nodeTransform);\n        }\n        const top = this.transform;\n        if (!top)\n            this._stack.push(nodeTransform);\n        else\n            this._stack.push(nodeTransform ? top.multiplyTransformTransform(nodeTransform) : top);\n    }\n    pop() {\n        assert(this._stack.length > 0);\n        this._stack.pop();\n    }\n}\nfunction compareTextureKeys(lhs, rhs) {\n    const cmp = compareBooleans(lhs.isTransparent, rhs.isTransparent);\n    if (0 !== cmp)\n        return cmp;\n    assert(typeof lhs.id === typeof rhs.id);\n    if (\"string\" === typeof lhs.id) {\n        assert(\"string\" === typeof rhs.id);\n        return compareStrings(lhs.id, rhs.id);\n    }\n    assert(\"number\" === typeof lhs.id && \"number\" === typeof rhs.id);\n    return compareNumbers(lhs.id, rhs.id);\n}\n/** Deserializes [glTF](https://www.khronos.org/gltf/).\n * @internal\n */\nexport class GltfReader {\n    get _nodes() { return this._glTF.nodes ?? emptyDict; }\n    get _meshes() { return this._glTF.meshes ?? emptyDict; }\n    get _accessors() { return this._glTF.accessors ?? emptyDict; }\n    get _bufferViews() { return this._glTF.bufferViews ?? emptyDict; }\n    get _materials() { return this._glTF.materials ?? emptyDict; }\n    get _samplers() { return this._glTF.samplers ?? emptyDict; }\n    get _textures() { return this._glTF.textures ?? emptyDict; }\n    get _images() { return this._glTF.images ?? emptyDict; }\n    get _buffers() { return this._glTF.buffers ?? emptyDict; }\n    get _isCanceled() { return undefined !== this._canceled && this._canceled(this); }\n    get _isVolumeClassifier() { return BatchType.VolumeClassifier === this._type; }\n    /** Traverse the nodes specified by their Ids, recursing into their child nodes.\n     * @param nodeIds The Ids of the nodes to traverse.\n     * @throws Error if a node appears more than once during traversal\n     */\n    traverseNodes(nodeIds) {\n        return traverseGltfNodes(nodeIds, this._nodes, new Set());\n    }\n    /** Traverse the nodes specified by their scene, recursing into their child nodes.\n     * @throws Error if a node appears more than once during traversal\n     */\n    traverseScene() {\n        return this.traverseNodes(this._sceneNodes);\n    }\n    getTileTransform(transformToRoot, pseudoRtcBias) {\n        let transform;\n        if (this._returnToCenter || pseudoRtcBias || this._yAxisUp || transformToRoot) {\n            if (this._returnToCenter)\n                transform = Transform.createTranslation(this._returnToCenter.clone());\n            else if (pseudoRtcBias)\n                transform = Transform.createTranslationXYZ(pseudoRtcBias.x, pseudoRtcBias.y, pseudoRtcBias.z);\n            else\n                transform = Transform.createIdentity();\n            if (this._yAxisUp)\n                transform = transform.multiplyTransformMatrix3d(Matrix3d.createRotationAroundVector(Vector3d.create(1.0, 0.0, 0.0), Angle.createRadians(Angle.piOver2Radians)));\n            if (transformToRoot)\n                transform = transformToRoot.multiplyTransformTransform(transform);\n        }\n        return transform;\n    }\n    readGltfAndCreateGraphics(isLeaf, featureTable, contentRange, transformToRoot, pseudoRtcBias, instances) {\n        if (this._isCanceled)\n            return { readStatus: TileReadStatus.Canceled, isLeaf };\n        // If contentRange was not supplied, we will compute it as we read the meshes.\n        if (!contentRange)\n            this._computedContentRange = contentRange = Range3d.createNull();\n        else\n            this._computedContentRange = undefined;\n        // ###TODO this looks like a hack? Why does it assume the first node's transform is special, or that the transform will be specified as a matrix instead of translation+rot+scale?\n        if (this._returnToCenter || this._nodes[0]?.matrix || (pseudoRtcBias && pseudoRtcBias.magnitude() < 1.0E5))\n            pseudoRtcBias = undefined;\n        const transformStack = new TransformStack();\n        const renderGraphicList = [];\n        let readStatus = TileReadStatus.InvalidTileData;\n        for (const nodeKey of this._sceneNodes) {\n            assert(transformStack.isEmpty);\n            const node = this._nodes[nodeKey];\n            if (node && TileReadStatus.Success !== (readStatus = this.readNodeAndCreateGraphics(renderGraphicList, node, featureTable, transformStack, instances, pseudoRtcBias)))\n                return { readStatus, isLeaf };\n        }\n        if (0 === renderGraphicList.length)\n            return { readStatus: TileReadStatus.InvalidTileData, isLeaf };\n        let renderGraphic;\n        if (1 === renderGraphicList.length)\n            renderGraphic = renderGraphicList[0];\n        else\n            renderGraphic = this._system.createGraphicList(renderGraphicList);\n        const transform = this.getTileTransform(transformToRoot, pseudoRtcBias);\n        let range = contentRange;\n        const invTransform = transform?.inverse();\n        if (invTransform)\n            range = invTransform.multiplyRange(contentRange);\n        if (featureTable)\n            renderGraphic = this._system.createBatch(renderGraphic, PackedFeatureTable.pack(featureTable), range);\n        if (transform) {\n            const branch = new GraphicBranch(true);\n            branch.add(renderGraphic);\n            renderGraphic = this._system.createBranch(branch, transform);\n        }\n        return {\n            readStatus,\n            isLeaf,\n            contentRange,\n            range,\n            graphic: renderGraphic,\n            containsPointCloud: this._containsPointCloud,\n        };\n    }\n    readGltfAndCreateGeometry(transformToRoot, needNormals = false, needParams = false) {\n        const transformStack = new TransformStack(this.getTileTransform(transformToRoot));\n        const polyfaces = [];\n        for (const nodeKey of this._sceneNodes) {\n            const node = this._nodes[nodeKey];\n            if (node)\n                this.readNodeAndCreatePolyfaces(polyfaces, node, transformStack, needNormals, needParams);\n        }\n        return { polyfaces };\n    }\n    graphicFromMeshData(gltfMesh, instances) {\n        if (\"pointcloud\" === gltfMesh.type)\n            return this._system.createPointCloud(gltfMesh, this._iModel);\n        if (!gltfMesh.points || !gltfMesh.pointRange)\n            return gltfMesh.primitive.getGraphics(this._system, instances);\n        const realityMeshPrimitive = (this._vertexTableRequired || instances) ? undefined : RealityMeshParams.fromGltfMesh(gltfMesh);\n        if (realityMeshPrimitive) {\n            const realityMesh = this._system.createRealityMesh(realityMeshPrimitive);\n            if (realityMesh)\n                return realityMesh;\n        }\n        const mesh = gltfMesh.primitive;\n        const pointCount = gltfMesh.points.length / 3;\n        assert(mesh.points instanceof QPoint3dList);\n        mesh.points.fromTypedArray(gltfMesh.pointRange, gltfMesh.points);\n        if (mesh.triangles && gltfMesh.indices)\n            mesh.triangles.addFromTypedArray(gltfMesh.indices);\n        if (gltfMesh.uvs && gltfMesh.uvRange && gltfMesh.uvQParams) {\n            /** This is ugly and inefficient... unnecessary if Mesh stored uvs as QPoint2dList */\n            for (let i = 0, j = 0; i < pointCount; i++)\n                mesh.uvParams.push(gltfMesh.uvQParams.unquantize(gltfMesh.uvs[j++], gltfMesh.uvs[j++]));\n        }\n        if (gltfMesh.normals)\n            for (const normal of gltfMesh.normals)\n                mesh.normals.push(new OctEncodedNormal(normal));\n        return mesh.getGraphics(this._system, instances);\n    }\n    readNodeAndCreateGraphics(renderGraphicList, node, featureTable, transformStack, instances, pseudoRtcBias) {\n        if (undefined === node)\n            return TileReadStatus.InvalidTileData;\n        // IMPORTANT: Do not return without popping this node from the stack.\n        transformStack.push(node);\n        const thisTransform = transformStack.transform;\n        /**\n         * This is a workaround for tiles generated by\n         * context capture which have a large offset from the tileset origin that exceeds the\n         * capacity of 32 bit integers. It is essentially an ad hoc RTC applied at read time only if the tile is far from the\n         * origin and there is no RTC supplied either with the B3DM of the GLTF.\n         * as the vertices are supplied in a quantized format, applying the RTC bias to\n         * quantization origin will make these tiles work correctly.\n         */\n        let thisBias;\n        if (undefined !== pseudoRtcBias)\n            thisBias = (undefined === thisTransform) ? pseudoRtcBias : thisTransform.matrix.multiplyInverse(pseudoRtcBias);\n        for (const meshKey of getGltfNodeMeshIds(node)) {\n            const nodeMesh = this._meshes[meshKey];\n            if (nodeMesh?.primitives) {\n                const meshes = this.readMeshPrimitives(node, featureTable, thisTransform, thisBias);\n                let renderGraphic;\n                if (0 !== meshes.length) {\n                    if (1 === meshes.length) {\n                        renderGraphic = this.graphicFromMeshData(meshes[0], instances);\n                    }\n                    else {\n                        const thisList = [];\n                        for (const mesh of meshes) {\n                            renderGraphic = this.graphicFromMeshData(mesh, instances);\n                            if (undefined !== renderGraphic)\n                                thisList.push(renderGraphic);\n                        }\n                        if (0 !== thisList.length)\n                            renderGraphic = this._system.createGraphicList(thisList);\n                    }\n                    if (renderGraphic) {\n                        if (thisTransform && !thisTransform.isIdentity) {\n                            const branch = new GraphicBranch(true);\n                            branch.add(renderGraphic);\n                            renderGraphic = this._system.createBranch(branch, thisTransform);\n                        }\n                        renderGraphicList.push(renderGraphic);\n                    }\n                }\n            }\n        }\n        if (node.children) {\n            for (const childId of node.children) {\n                const child = this._nodes[childId];\n                if (child)\n                    this.readNodeAndCreateGraphics(renderGraphicList, child, featureTable, transformStack, instances);\n            }\n        }\n        transformStack.pop();\n        return TileReadStatus.Success;\n    }\n    readNodeAndCreatePolyfaces(polyfaces, node, transformStack, needNormals, needParams) {\n        // IMPORTANT: Do not return without popping this node from the stack.\n        transformStack.push(node);\n        const meshes = this.readMeshPrimitives(node);\n        for (const mesh of meshes) {\n            if (mesh.type === \"mesh\") {\n                const polyface = this.polyfaceFromGltfMesh(mesh, transformStack.transform, needNormals, needParams);\n                if (polyface)\n                    polyfaces.push(polyface);\n            }\n        }\n        if (node.children) {\n            for (const childId of node.children) {\n                const child = this._nodes[childId];\n                if (child)\n                    this.readNodeAndCreatePolyfaces(polyfaces, child, transformStack, needNormals, needParams);\n            }\n        }\n    }\n    polyfaceFromGltfMesh(mesh, transform, needNormals, needParams) {\n        if (!mesh.pointQParams || !mesh.points || !mesh.indices)\n            return undefined;\n        const { points, pointQParams, normals, uvs, uvQParams, indices } = mesh;\n        const includeNormals = needNormals && undefined !== normals;\n        const includeParams = needParams && undefined !== uvQParams && undefined !== uvs;\n        const polyface = IndexedPolyface.create(includeNormals, includeParams);\n        for (let i = 0; i < points.length;) {\n            const point = pointQParams.unquantize(points[i++], points[i++], points[i++]);\n            if (transform)\n                transform.multiplyPoint3d(point, point);\n            polyface.addPoint(point);\n        }\n        if (includeNormals && normals)\n            for (let i = 0; i < normals.length;)\n                polyface.addNormal(OctEncodedNormal.decodeValue(normals[i++]));\n        if (includeParams && uvs && uvQParams)\n            for (let i = 0; i < uvs.length;)\n                polyface.addParam(uvQParams.unquantize(uvs[i++], uvs[i++]));\n        let j = 0;\n        for (const index of indices) {\n            polyface.addPointIndex(index);\n            if (includeNormals)\n                polyface.addNormalIndex(index);\n            if (includeParams)\n                polyface.addParamIndex(index);\n            if (0 === (++j % 3))\n                polyface.terminateFacet();\n        }\n        return polyface;\n    }\n    // ###TODO what is the actual type of `json`?\n    getBufferView(json, accessorName) {\n        try {\n            const accessorValue = JsonUtils.asString(json[accessorName]);\n            const accessor = accessorValue ? this._accessors[accessorValue] : undefined;\n            if (!accessor)\n                return undefined;\n            const bufferViewAccessorValue = accessor.bufferView;\n            const bufferView = undefined !== bufferViewAccessorValue ? this._bufferViews[bufferViewAccessorValue] : undefined;\n            if (!bufferView || undefined === bufferView.buffer)\n                return undefined;\n            const buffer = this._buffers[bufferView.buffer];\n            const bufferData = buffer?.resolvedBuffer;\n            if (!bufferData)\n                return undefined;\n            const type = accessor.componentType;\n            let dataSize = 0;\n            switch (type) {\n                case GltfDataType.UnsignedByte:\n                    dataSize = 1;\n                    break;\n                case GltfDataType.UnsignedShort:\n                    dataSize = 2;\n                    break;\n                case GltfDataType.UInt32:\n                case GltfDataType.Float:\n                    dataSize = 4;\n                    break;\n                default:\n                    return undefined;\n            }\n            let componentCount = 1;\n            switch (accessor.type) {\n                case \"VEC4\":\n                    componentCount = 4;\n                    break;\n                case \"VEC3\":\n                    componentCount = 3;\n                    break;\n                case \"VEC2\":\n                    componentCount = 2;\n                    break;\n            }\n            const byteStride = bufferView.byteStride ? bufferView.byteStride : componentCount * dataSize;\n            const offset = ((bufferView && bufferView.byteOffset) ? bufferView.byteOffset : 0) + (accessor.byteOffset ? accessor.byteOffset : 0);\n            const length = byteStride * accessor.count;\n            // If the data is misaligned (Scalable mesh tile publisher) use slice to copy -- else use subarray.\n            const aligned = 0 === (bufferData.byteOffset + offset) % dataSize;\n            const bytes = aligned ? bufferData.subarray(offset, offset + length) : bufferData.slice(offset, offset + length);\n            return new GltfBufferView(bytes, accessor.count, type, accessor, byteStride / dataSize);\n        }\n        catch (e) {\n            return undefined;\n        }\n    }\n    readBufferData32(json, accessorName) { return this.readBufferData(json, accessorName, GltfDataType.UInt32); }\n    readBufferData16(json, accessorName) { return this.readBufferData(json, accessorName, GltfDataType.UnsignedShort); }\n    readBufferData8(json, accessorName) { return this.readBufferData(json, accessorName, GltfDataType.UnsignedByte); }\n    readBufferDataFloat(json, accessorName) { return this.readBufferData(json, accessorName, GltfDataType.Float); }\n    constructor(args) {\n        this._resolvedTextures = new Dictionary((lhs, rhs) => compareTextureKeys(lhs, rhs));\n        this._dracoMeshes = new Map();\n        this._containsPointCloud = false;\n        /** The glTF spec says that if GltfSampler.wrapS/T are omitted, they default to Repeat.\n         * However, the reality data service serves tiles that lack any wrapS/T property, and we want those clamped to edge, not repeated.\n         * (We also don't want to produce mip-maps for them, which is determined indirectly from the wrap mode).\n         * Allow the default to be optionally overridden.\n         */\n        this.defaultWrapMode = GltfWrapMode.Repeat;\n        this._glTF = args.props.glTF;\n        this._version = args.props.version;\n        this._yAxisUp = args.props.yAxisUp;\n        this._baseUrl = args.props.baseUrl;\n        const rtcCenter = args.props.glTF.extensions?.CESIUM_RTC?.center;\n        if (rtcCenter && 3 === rtcCenter.length)\n            if (0 !== rtcCenter[0] || 0 !== rtcCenter[1] || 0 !== rtcCenter[2])\n                this._returnToCenter = Point3d.fromJSON(rtcCenter);\n        this._iModel = args.iModel;\n        this._is3d = true !== args.is2d;\n        this._system = args.system ?? IModelApp.renderSystem;\n        this._type = args.type ?? BatchType.Primary;\n        this._canceled = args.shouldAbort;\n        this._deduplicateVertices = args.deduplicateVertices ?? false;\n        this._vertexTableRequired = args.vertexTableRequired ?? false;\n        const binaryData = args.props.binaryData;\n        if (binaryData) {\n            const buffer = this._buffers[this._version === 2 ? 0 : \"binary_glTF\"];\n            if (buffer && undefined === buffer.uri)\n                buffer.resolvedBuffer = binaryData;\n        }\n        // The original implementation of GltfReader would process and produce graphics for every node in glTF.nodes.\n        // What it's *supposed* to do is process the nodes in glTF.scenes[glTF.scene].nodes\n        // Some nodes may not be referenced by the configured scene, or only indirectly via GltfNode.children.\n        // Perhaps some faulty tiles existed that didn't define their scenes properly?\n        let sceneNodes;\n        if (this._glTF.scenes && undefined !== this._glTF.scene)\n            sceneNodes = this._glTF.scenes[this._glTF.scene]?.nodes;\n        if (!sceneNodes)\n            sceneNodes = Object.keys(this._nodes);\n        this._sceneNodes = sceneNodes;\n    }\n    readBufferData(json, accessorName, type) {\n        const view = this.getBufferView(json, accessorName);\n        return undefined !== view ? view.toBufferData(type) : undefined;\n    }\n    readFeatureIndices(_json) { return undefined; }\n    extractId(value) {\n        switch (typeof value) {\n            case \"string\":\n                return value;\n            case \"number\":\n                return value.toString();\n            default:\n                return undefined;\n        }\n    }\n    extractTextureId(material) {\n        if (typeof material !== \"object\")\n            return undefined;\n        // Bimium's shader value...almost certainly obsolete at this point.\n        if (isGltf1Material(material))\n            return material.diffuse ?? this.extractId(material.values?.tex);\n        // KHR_techniques_webgl extension\n        const techniques = this._glTF.extensions?.KHR_techniques_webgl?.techniques;\n        const ext = Array.isArray(techniques) ? material.extensions?.KHR_techniques_webgl : undefined;\n        if (techniques && undefined !== ext && typeof (ext.values) === \"object\") {\n            const uniforms = typeof ext.technique === \"number\" ? techniques[ext.technique].uniforms : undefined;\n            if (typeof uniforms === \"object\") {\n                for (const uniformName of Object.keys(uniforms)) {\n                    const uniform = uniforms[uniformName];\n                    if (typeof uniform === \"object\" && uniform.type === GltfDataType.Sampler2d)\n                        return this.extractId(ext.values[uniformName]?.index);\n                }\n            }\n        }\n        const id = this.extractId(material.pbrMetallicRoughness?.baseColorTexture?.index);\n        return id ?? this.extractId(material.emissiveTexture?.index);\n    }\n    extractNormalMapId(material) {\n        if (typeof material !== \"object\")\n            return undefined;\n        if (isGltf1Material(material))\n            return undefined;\n        return this.extractId(material.normalTexture?.index);\n    }\n    isMaterialTransparent(material) {\n        if (isGltf1Material(material)) {\n            if (this._glTF.techniques && undefined !== material.technique) {\n                const technique = this._glTF.techniques[material.technique];\n                if (technique?.states?.enable?.some((state) => state === GltfTechniqueState.Blend))\n                    return true;\n            }\n            return false;\n        }\n        else {\n            // Default: OPAQUE.\n            // ###TODO support MASK. For now treat as opaque.\n            return \"BLEND\" === material.alphaMode;\n        }\n    }\n    createDisplayParams(material, hasBakedLighting) {\n        const isTransparent = this.isMaterialTransparent(material);\n        const textureId = this.extractTextureId(material);\n        const normalMapId = this.extractNormalMapId(material);\n        let textureMapping = (undefined !== textureId || undefined !== normalMapId) ? this.findTextureMapping(textureId, isTransparent, normalMapId) : undefined;\n        const color = colorFromMaterial(material, isTransparent);\n        let renderMaterial;\n        if (undefined !== textureMapping && undefined !== textureMapping.normalMapParams) {\n            const args = { diffuse: { color }, specular: { color: ColorDef.white }, textureMapping };\n            renderMaterial = IModelApp.renderSystem.createRenderMaterial(args);\n            // DisplayParams doesn't want a separate texture mapping if the material already has one.\n            textureMapping = undefined;\n        }\n        return new DisplayParams(DisplayParams.Type.Mesh, color, color, 1, LinePixels.Solid, FillFlags.Always, renderMaterial, undefined, hasBakedLighting, textureMapping);\n    }\n    readMeshPrimitives(node, featureTable, thisTransform, thisBias) {\n        const meshes = [];\n        for (const meshKey of getGltfNodeMeshIds(node)) {\n            const nodeMesh = this._meshes[meshKey];\n            if (nodeMesh?.primitives) {\n                for (const primitive of nodeMesh.primitives) {\n                    const mesh = this.readMeshPrimitive(primitive, featureTable, thisBias);\n                    if (mesh) {\n                        meshes.push(mesh);\n                        if (this._computedContentRange && mesh.pointRange) {\n                            const invTransform = thisTransform?.inverse();\n                            const meshRange = invTransform ? invTransform.multiplyRange(mesh.pointRange) : mesh.pointRange;\n                            this._computedContentRange.extendRange(meshRange);\n                        }\n                    }\n                }\n            }\n        }\n        return meshes;\n    }\n    readMeshPrimitive(primitive, featureTable, pseudoRtcBias) {\n        const meshMode = JsonUtils.asInt(primitive.mode, GltfMeshMode.Triangles);\n        if (meshMode === GltfMeshMode.Points /* && !this._vertexTableRequired */) {\n            const pointCloud = this.readPointCloud(primitive, undefined !== featureTable);\n            if (pointCloud)\n                return pointCloud;\n        }\n        const materialName = JsonUtils.asString(primitive.material);\n        const material = 0 < materialName.length ? this._materials[materialName] : {};\n        if (!material)\n            return undefined;\n        const hasBakedLighting = undefined === primitive.attributes.NORMAL || undefined !== material.extensions?.KHR_materials_unlit;\n        const displayParams = material ? this.createDisplayParams(material, hasBakedLighting) : undefined;\n        if (!displayParams)\n            return undefined;\n        let primitiveType = -1;\n        switch (meshMode) {\n            case GltfMeshMode.Lines:\n                primitiveType = MeshPrimitiveType.Polyline;\n                break;\n            case GltfMeshMode.Points:\n                primitiveType = MeshPrimitiveType.Point;\n                break;\n            case GltfMeshMode.Triangles:\n                primitiveType = MeshPrimitiveType.Mesh;\n                break;\n            default:\n                return undefined;\n        }\n        const isVolumeClassifier = this._isVolumeClassifier;\n        const meshPrimitive = Mesh.create({\n            displayParams,\n            features: featureTable,\n            type: primitiveType,\n            range: Range3d.createNull(),\n            is2d: !this._is3d,\n            isPlanar: false,\n            hasBakedLighting,\n            isVolumeClassifier,\n            quantizePositions: true,\n        });\n        const mesh = new GltfMeshData(meshPrimitive);\n        // ###TODO_GLTF: There can be more than one color attribute; COLOR_0 might not be the one we want.\n        if (!this.readColors(mesh, primitive.attributes, \"COLOR_0\")) {\n            // We don't have real colormap - just load material color.  This will be used if non-Bentley\n            // tile or fit the color table is uniform. For a non-Bentley, non-Uniform, we'll set the\n            // uv parameters to pick the colors out of the color map texture.\n            meshPrimitive.colorMap.insert(displayParams.fillColor.tbgr); // White...\n            // _COLORINDEX is an ancient holdover from glTF 1.0 and Bimium...unlikely to actually encounter it in the wild.\n            const colorIndices = this.readBufferData16(primitive.attributes, \"_COLORINDEX\");\n            if (undefined !== colorIndices && material) {\n                let texStep;\n                if (isGltf1Material(material))\n                    texStep = material.values?.texStep;\n                else\n                    texStep = material.extensions?.KHR_techniques_webgl?.values?.u_texStep;\n                if (texStep) {\n                    const uvParams = [];\n                    for (let i = 0; i < colorIndices.count; i++)\n                        uvParams.push(new Point2d(texStep[1] + texStep[0] * colorIndices.buffer[i], .5));\n                    const paramList = QPoint2dList.fromPoints(uvParams);\n                    mesh.uvs = paramList.toTypedArray();\n                    mesh.uvQParams = paramList.params;\n                }\n            }\n        }\n        const draco = primitive.extensions?.KHR_draco_mesh_compression;\n        if (draco)\n            return this.readDracoMeshPrimitive(mesh.primitive, draco) ? mesh : undefined;\n        this.readBatchTable(mesh.primitive, primitive);\n        if (mesh.primitive.features) {\n            const features = this.readPrimitiveFeatures(primitive);\n            if (features) {\n                if (features instanceof Feature)\n                    mesh.primitive.features.add(features, 1);\n                else\n                    mesh.primitive.features.setIndices(features);\n            }\n        }\n        if (!this.readVertices(mesh, primitive, pseudoRtcBias))\n            return undefined;\n        switch (primitiveType) {\n            case MeshPrimitiveType.Mesh: {\n                if (!this.readMeshIndices(mesh, primitive))\n                    return undefined;\n                if (!displayParams.ignoreLighting && !this.readNormals(mesh, primitive.attributes, \"NORMAL\"))\n                    return undefined;\n                if (!mesh.uvs) {\n                    let texCoordIndex = 0;\n                    if (!isGltf1Material(material) && undefined !== material.pbrMetallicRoughness?.baseColorTexture?.texCoord)\n                        texCoordIndex = JsonUtils.asInt(material.pbrMetallicRoughness.baseColorTexture.texCoord);\n                    this.readUVParams(mesh, primitive.attributes, `TEXCOORD_${texCoordIndex}`);\n                }\n                if (this._deduplicateVertices && !this.deduplicateVertices(mesh))\n                    return undefined;\n                break;\n            }\n            case MeshPrimitiveType.Polyline:\n            case MeshPrimitiveType.Point: {\n                if (undefined !== mesh.primitive.polylines && !this.readPolylines(mesh.primitive.polylines, primitive, \"indices\", MeshPrimitiveType.Point === primitiveType))\n                    return undefined;\n                break;\n            }\n            default: {\n                assert(false, \"unhandled primitive type\");\n                return undefined;\n            }\n        }\n        if (displayParams.textureMapping && !mesh.uvs)\n            return undefined;\n        if (primitive.extensions?.CESIUM_primitive_outline) {\n            const data = this.readBufferData32(primitive.extensions.CESIUM_primitive_outline, \"indices\");\n            if (data !== undefined) {\n                assert(0 === data.count % 2);\n                mesh.primitive.edges = new MeshEdges();\n                for (let i = 0; i < data.count;)\n                    mesh.primitive.edges.visible.push(new MeshEdge(data.buffer[i++], data.buffer[i++]));\n            }\n        }\n        return mesh;\n    }\n    readPointCloud(primitive, hasFeatures) {\n        const posView = this.getBufferView(primitive.attributes, \"POSITION\");\n        if (!posView || GltfDataType.Float !== posView.type)\n            return undefined;\n        const posData = posView.toBufferData(GltfDataType.Float);\n        if (!(posData?.buffer instanceof Float32Array))\n            return undefined;\n        const colorView = this.getBufferView(primitive.attributes, \"COLOR_0\");\n        if (!colorView || GltfDataType.UnsignedByte !== colorView.type)\n            return undefined;\n        const colorData = colorView.toBufferData(GltfDataType.UnsignedByte);\n        if (!(colorData?.buffer instanceof Uint8Array))\n            return undefined;\n        const strideSkip = posView.stride - 3;\n        const pointRange = new Range3d();\n        for (let i = 0; i < posData.buffer.length; i += strideSkip)\n            pointRange.extendXYZ(posData.buffer[i++], posData.buffer[i++], posData.buffer[i++]);\n        let colors = colorData.buffer;\n        if (\"VEC4\" === colorView.accessor.type) {\n            // ###TODO support transparent point clouds\n            colors = new Uint8Array(colorData.count * 3);\n            for (let i = 0; i < colorData.count; i++) {\n                const srcIdx = colorView.stride * i;\n                const dstIdx = 3 * i;\n                for (let j = 0; j < 3; j++)\n                    colors[dstIdx + j] = colorData.buffer[srcIdx + j];\n            }\n        }\n        const features = new FeatureIndex();\n        if (hasFeatures)\n            features.type = FeatureIndexType.Uniform;\n        this._containsPointCloud = true;\n        return {\n            type: \"pointcloud\",\n            positions: posData.buffer,\n            qparams: QParams3d.fromOriginAndScale(new Point3d(0, 0, 0), new Point3d(1, 1, 1)),\n            pointRange,\n            colors,\n            colorFormat: \"rgb\",\n            features,\n            // ###TODO: If tile does not use additive refinement, compute voxelSize based on point range.\n            // Additive refinement is typical of the glTF point clouds we receive from Orbit.\n            voxelSize: 0,\n        };\n    }\n    readDracoMeshPrimitive(mesh, ext) {\n        const draco = this._dracoMeshes.get(ext);\n        if (!draco || \"triangle-list\" !== draco.topology)\n            return false;\n        const indices = draco.indices?.value;\n        if (!indices || (indices.length % 3) !== 0)\n            return false;\n        const pos = draco.attributes.POSITION?.value;\n        if (!pos || (pos.length % 3) !== 0)\n            return false;\n        // ###TODO: I have yet to see a draco-encoded mesh with interleaved attributes. Currently not checking.\n        const triangle = new Triangle();\n        for (let i = 0; i < indices.length; i += 3) {\n            triangle.setIndices(indices[i], indices[i + 1], indices[i + 2]);\n            mesh.addTriangle(triangle);\n        }\n        let posRange;\n        const bbox = draco.header?.boundingBox;\n        if (bbox) {\n            posRange = Range3d.createXYZXYZ(bbox[0][0], bbox[0][1], bbox[0][2], bbox[1][0], bbox[1][1], bbox[1][2]);\n        }\n        else {\n            posRange = Range3d.createNull();\n            for (let i = 0; i < pos.length; i += 3)\n                posRange.extendXYZ(pos[i], pos[i + 1], pos[i + 2]);\n        }\n        assert(mesh.points instanceof QPoint3dList);\n        mesh.points.params.setFromRange(posRange);\n        const pt = Point3d.createZero();\n        for (let i = 0; i < pos.length; i += 3) {\n            pt.set(pos[i], pos[i + 1], pos[i + 2]);\n            mesh.points.add(pt);\n        }\n        const normals = draco.attributes.NORMAL?.value;\n        if (normals && (normals.length % 3) === 0) {\n            const vec = Vector3d.createZero();\n            for (let i = 0; i < normals.length; i += 3) {\n                vec.set(normals[i], normals[i + 1], normals[i + 2]);\n                mesh.normals.push(OctEncodedNormal.fromVector(vec));\n            }\n        }\n        const uvs = draco.attributes.TEXCOORD_0?.value;\n        if (uvs && (uvs.length % 2) === 0)\n            for (let i = 0; i < uvs.length; i += 2)\n                mesh.uvParams.push(new Point2d(uvs[i], uvs[i + 1]));\n        const batchIds = draco.attributes._BATCHID?.value;\n        if (batchIds && mesh.features) {\n            const featureIndices = [];\n            for (const batchId of batchIds)\n                featureIndices.push(batchId);\n            mesh.features.setIndices(featureIndices);\n        }\n        return true;\n    }\n    deduplicateVertices(mesh) {\n        if (!mesh.points || !mesh.indices)\n            return false;\n        const numPoints = mesh.indices.length;\n        assert(0 === numPoints % 3);\n        const indices = mesh.indices;\n        if (indices instanceof Uint16Array && numPoints > 0xffff)\n            mesh.indices = new Uint32Array(numPoints);\n        else if (indices instanceof Uint8Array && numPoints > 0xff)\n            mesh.indices = new Uint32Array(numPoints);\n        const points = new Uint16Array(3 * numPoints);\n        const normals = mesh.normals ? new Uint16Array(numPoints) : undefined;\n        const uvs = mesh.uvs ? new Uint16Array(2 * numPoints) : undefined;\n        for (let i = 0; i < numPoints; i++) {\n            const index = indices[i];\n            mesh.indices[i] = i;\n            points[i * 3 + 0] = mesh.points[index * 3 + 0];\n            points[i * 3 + 1] = mesh.points[index * 3 + 1];\n            points[i * 3 + 2] = mesh.points[index * 3 + 2];\n            if (normals)\n                normals[i] = mesh.normals[index];\n            if (uvs) {\n                uvs[i * 2 + 0] = mesh.uvs[index * 2 + 0];\n                uvs[i * 2 + 1] = mesh.uvs[index * 2 + 1];\n            }\n        }\n        mesh.points = points;\n        mesh.normals = normals;\n        mesh.uvs = uvs;\n        return true;\n    }\n    /**\n     *\n     * @param positions quantized points\n     * @param primitive input json\n     * @param pseudoRtcBias a bias applied to each point - this is a workaround for tiles generated by\n     * context capture which have a large offset from the tileset origin that exceeds the\n     * capacity of 32 bit integers. This is essentially an ad hoc RTC applied at read time.\n     */\n    readVertices(mesh, primitive, pseudoRtcBias) {\n        const view = this.getBufferView(primitive.attributes, \"POSITION\");\n        if (undefined === view)\n            return false;\n        if (GltfDataType.Float === view.type) {\n            const buffer = view.toBufferData(GltfDataType.Float);\n            if (undefined === buffer)\n                return false;\n            const strideSkip = view.stride - 3;\n            mesh.pointRange = Range3d.createNull();\n            for (let i = 0; i < buffer.buffer.length; i += strideSkip)\n                mesh.pointRange.extendXYZ(buffer.buffer[i++], buffer.buffer[i++], buffer.buffer[i++]);\n            const positions = new QPoint3dList(QParams3d.fromRange(mesh.pointRange));\n            const scratchPoint = new Point3d();\n            for (let i = 0, j = 0; i < buffer.count; i++, j += strideSkip) {\n                scratchPoint.set(buffer.buffer[j++], buffer.buffer[j++], buffer.buffer[j++]);\n                if (undefined !== pseudoRtcBias)\n                    scratchPoint.subtractInPlace(pseudoRtcBias);\n                positions.add(scratchPoint);\n            }\n            mesh.pointQParams = positions.params;\n            mesh.points = positions.toTypedArray();\n        }\n        else {\n            if (GltfDataType.UnsignedShort !== view.type)\n                return false;\n            const quantized = view.accessor.extensions?.WEB3D_quantized_attributes;\n            const rangeMin = quantized?.decodedMin;\n            const rangeMax = quantized?.decodedMax;\n            if (!rangeMin || !rangeMax) // required by spec...\n                return false;\n            // ###TODO apply WEB3D_quantized_attributes.decodeMatrix? Have not encountered in the wild; glTF 1.0 only.\n            const buffer = view.toBufferData(GltfDataType.UnsignedShort);\n            if (undefined === buffer || !(buffer.buffer instanceof Uint16Array))\n                return false;\n            assert(buffer.buffer instanceof Uint16Array);\n            mesh.pointRange = Range3d.createXYZXYZ(rangeMin[0], rangeMin[1], rangeMin[2], rangeMax[0], rangeMax[1], rangeMax[2]);\n            if (undefined !== pseudoRtcBias) {\n                mesh.pointRange.low.subtractInPlace(pseudoRtcBias);\n                mesh.pointRange.high.subtractInPlace(pseudoRtcBias);\n            }\n            mesh.pointQParams = QParams3d.fromRange(mesh.pointRange);\n            if (3 === view.stride) {\n                mesh.points = buffer.buffer;\n            }\n            else {\n                mesh.points = new Uint16Array(3 * view.count);\n                for (let i = 0, j = 0; i < view.count; i++) {\n                    const index = i * view.stride;\n                    mesh.points[j++] = buffer.buffer[index];\n                    mesh.points[j++] = buffer.buffer[index + 1];\n                    mesh.points[j++] = buffer.buffer[index + 2];\n                }\n            }\n        }\n        return true;\n    }\n    readIndices(json, accessorName) {\n        const data = this.readBufferData32(json, accessorName);\n        if (undefined === data)\n            return undefined;\n        const indices = [];\n        for (let i = 0; i < data.count; i++)\n            indices.push(data.buffer[i]);\n        return indices;\n    }\n    readBatchTable(_mesh, _json) {\n    }\n    readPrimitiveFeatures(_primitive) {\n        return undefined;\n    }\n    readMeshIndices(mesh, json) {\n        if (undefined !== json.indices) {\n            const data = this.readBufferData16(json, \"indices\") || this.readBufferData32(json, \"indices\");\n            if (data && (data.buffer instanceof Uint8Array || data.buffer instanceof Uint16Array || data.buffer instanceof Uint32Array)) {\n                mesh.indices = data.buffer;\n                return true;\n            }\n            return false;\n        }\n        // Non-indexed geometry. Manufacture triangle indices from points.\n        const numPoints = mesh.points?.length;\n        if (undefined === numPoints || 0 !== numPoints % 3)\n            return false;\n        mesh.indices = numPoints < 255 ? new Uint8Array(numPoints) : (numPoints < 0xffff ? new Uint16Array(numPoints) : new Uint32Array(numPoints));\n        for (let i = 0; i < numPoints; i++)\n            mesh.indices[i] = i;\n        return true;\n    }\n    readNormals(mesh, json, accessorName) {\n        const view = this.getBufferView(json, accessorName);\n        if (undefined === view)\n            return false;\n        switch (view.type) {\n            case GltfDataType.Float: {\n                const data = view.toBufferData(GltfDataType.Float);\n                if (undefined === data)\n                    return false;\n                mesh.normals = new Uint16Array(data.count);\n                const scratchNormal = new Vector3d();\n                const strideSkip = view.stride - 3;\n                for (let i = 0, j = 0; i < data.count; i++, j += strideSkip) {\n                    scratchNormal.set(data.buffer[j++], data.buffer[j++], data.buffer[j++]);\n                    mesh.normals[i] = OctEncodedNormal.encode(scratchNormal);\n                }\n                return true;\n            }\n            case GltfDataType.UnsignedByte: {\n                const data = view.toBufferData(GltfDataType.UnsignedByte);\n                if (undefined === data)\n                    return false;\n                // ###TODO: we shouldn't have to allocate OctEncodedNormal objects...just use uint16s / numbers...\n                mesh.normals = new Uint16Array(data.count);\n                for (let i = 0; i < data.count; i++) {\n                    // ###TODO? not clear why ray writes these as pairs of uint8...\n                    const index = i * view.stride;\n                    const normal = data.buffer[index] | (data.buffer[index + 1] << 8);\n                    mesh.normals[i] = normal;\n                }\n                return true;\n            }\n            default:\n                return false;\n        }\n    }\n    readColors(mesh, attribute, accessorName) {\n        const view = this.getBufferView(attribute, accessorName);\n        if (!view || (GltfDataType.Float !== view.type && GltfDataType.UnsignedByte !== view.type && GltfDataType.SignedByte !== view.type))\n            return false;\n        const data = view.toBufferData(view.type);\n        if (!data)\n            return false;\n        const hasAlpha = \"VEC4\" === view.accessor.type;\n        const factor = view.type === GltfDataType.Float ? 255 : 1;\n        const rgbt = new Uint8Array(4);\n        const color = new Uint32Array(rgbt.buffer);\n        for (let i = 0; i < data.count; i++) {\n            const index = view.stride * i;\n            rgbt[0] = data.buffer[index] * factor;\n            rgbt[1] = data.buffer[index + 1] * factor;\n            rgbt[2] = data.buffer[index + 2] * factor;\n            rgbt[3] = hasAlpha ? (255 - data.buffer[index + 3] * factor) : 0;\n            mesh.primitive.colors.push(mesh.primitive.colorMap.insert(color[0]));\n        }\n        return true;\n    }\n    readUVParams(mesh, json, accessorName) {\n        const view = this.getBufferView(json, accessorName);\n        if (view === undefined)\n            return false;\n        switch (view.type) {\n            case GltfDataType.Float: {\n                const data = this.readBufferDataFloat(json, accessorName);\n                if (!data)\n                    return false;\n                mesh.uvRange = Range2d.createNull();\n                for (let i = 0; i < data.count; i++) {\n                    const index = view.stride * i; // 2 float per param...\n                    mesh.uvRange.extendXY(data.buffer[index], data.buffer[index + 1]);\n                }\n                mesh.uvQParams = QParams2d.fromRange(mesh.uvRange);\n                mesh.uvs = new Uint16Array(data.count * 2);\n                for (let i = 0, j = 0; i < data.count; i++) {\n                    const index = view.stride * i; // 2 float per param...\n                    mesh.uvs[j++] = Quantization.quantize(data.buffer[index], mesh.uvQParams.origin.x, mesh.uvQParams.scale.x);\n                    mesh.uvs[j++] = Quantization.quantize(data.buffer[index + 1], mesh.uvQParams.origin.y, mesh.uvQParams.scale.y);\n                }\n                return true;\n            }\n            case GltfDataType.UnsignedShort: {\n                const quantized = view.accessor.extensions?.WEB3D_quantized_attributes;\n                const rangeMin = quantized?.decodedMin;\n                const rangeMax = quantized?.decodedMax;\n                if (undefined === rangeMin || undefined === rangeMax)\n                    return false;\n                const qData = view.toBufferData(GltfDataType.UnsignedShort);\n                if (undefined === qData || !(qData.buffer instanceof Uint16Array))\n                    return false;\n                mesh.uvRange = Range2d.createXYXY(rangeMin[0], rangeMin[1], rangeMax[0], rangeMax[1]);\n                mesh.uvQParams = QParams2d.fromRange(mesh.uvRange);\n                if (2 === view.stride) {\n                    mesh.uvs = qData.buffer;\n                }\n                else {\n                    mesh.uvs = new Uint16Array(2 * view.count);\n                    for (let i = 0, j = 0; i < view.count; i++) {\n                        const index = i * view.stride;\n                        mesh.uvs[j++] = qData.buffer[index];\n                        mesh.uvs[j++] = qData.buffer[index + 1];\n                    }\n                }\n                return true;\n            }\n            default:\n                assert(false);\n                return false;\n        }\n        return true;\n    }\n    readPolylines(polylines, json, accessorName, disjoint) {\n        const data = this.readBufferData32(json, accessorName);\n        if (undefined === data)\n            return false;\n        const indices = new Array();\n        if (disjoint) {\n            for (let i = 0; i < data.count;)\n                indices.push(data.buffer[i++]);\n        }\n        else {\n            for (let i = 0; i < data.count;) {\n                const index0 = data.buffer[i++];\n                const index1 = data.buffer[i++];\n                if (0 === indices.length || index0 !== indices[indices.length - 1]) {\n                    if (indices.length !== 0) {\n                        polylines.push(new MeshPolyline(indices));\n                        indices.length = 0;\n                    }\n                    indices.push(index0);\n                }\n                indices.push(index1);\n            }\n        }\n        if (indices.length !== 0)\n            polylines.push(new MeshPolyline(indices));\n        return true;\n    }\n    async resolveResources() {\n        // Load any external images and buffers.\n        await this._resolveResources();\n        // If any meshes are draco-compressed, dynamically load the decoder module and then decode the meshes.\n        const dracoMeshes = [];\n        for (const node of this.traverseScene()) {\n            for (const meshId of getGltfNodeMeshIds(node)) {\n                const mesh = this._meshes[meshId];\n                if (mesh?.primitives)\n                    for (const primitive of mesh.primitives)\n                        if (primitive.extensions?.KHR_draco_mesh_compression)\n                            dracoMeshes.push(primitive.extensions.KHR_draco_mesh_compression);\n            }\n        }\n        if (dracoMeshes.length === 0)\n            return;\n        try {\n            const dracoLoader = (await import(\"@loaders.gl/draco\")).DracoLoader;\n            await Promise.all(dracoMeshes.map(async (x) => this.decodeDracoMesh(x, dracoLoader)));\n        }\n        catch (err) {\n            Logger.logWarning(FrontendLoggerCategory.Render, \"Failed to decode draco-encoded glTF mesh\");\n            Logger.logException(FrontendLoggerCategory.Render, err);\n        }\n    }\n    async _resolveResources() {\n        // ###TODO traverse the scene nodes to find resources referenced by them, instead of resolving everything - some resources may not\n        // be required for the scene.\n        const promises = [];\n        try {\n            for (const buffer of gltfDictionaryIterator(this._buffers))\n                if (!buffer.resolvedBuffer)\n                    promises.push(this.resolveBuffer(buffer));\n            await Promise.all(promises);\n            if (this._isCanceled)\n                return;\n            promises.length = 0;\n            for (const image of gltfDictionaryIterator(this._images))\n                if (!image.resolvedImage)\n                    promises.push(this.resolveImage(image));\n            await Promise.all(promises);\n        }\n        catch (_) {\n        }\n    }\n    async decodeDracoMesh(ext, loader) {\n        const bv = this._bufferViews[ext.bufferView];\n        if (!bv || !bv.byteLength)\n            return;\n        let buf = this._buffers[bv.buffer]?.resolvedBuffer;\n        if (!buf)\n            return;\n        const offset = bv.byteOffset ?? 0;\n        buf = buf.subarray(offset, offset + bv.byteLength);\n        const mesh = await loader.parse(buf, {}); // NB: `options` argument declared optional but will produce exception if not supplied.\n        if (mesh)\n            this._dracoMeshes.set(ext, mesh);\n    }\n    resolveUrl(uri) {\n        try {\n            const resolved = new URL(uri, this._baseUrl);\n            resolved.search = this._baseUrl?.search ?? \"\";\n            return resolved.toString();\n        }\n        catch (_) {\n            return undefined;\n        }\n    }\n    async resolveBuffer(buffer) {\n        if (buffer.resolvedBuffer || undefined === buffer.uri)\n            return;\n        try {\n            const url = this.resolveUrl(buffer.uri);\n            const response = url ? await fetch(url) : undefined;\n            if (this._isCanceled)\n                return;\n            const data = await response?.arrayBuffer();\n            if (this._isCanceled)\n                return;\n            if (data)\n                buffer.resolvedBuffer = new Uint8Array(data);\n        }\n        catch (_) {\n            //\n        }\n    }\n    async resolveImage(image) {\n        if (image.resolvedImage)\n            return;\n        const bvSrc = undefined !== image.bufferView ? image : image.extensions?.KHR_binary_glTF;\n        if (undefined !== bvSrc?.bufferView) {\n            const format = undefined !== bvSrc.mimeType ? getImageSourceFormatForMimeType(bvSrc.mimeType) : undefined;\n            const bufferView = this._bufferViews[bvSrc.bufferView];\n            if (undefined === format || !bufferView || !bufferView.byteLength || bufferView.byteLength < 0)\n                return;\n            const bufferData = this._buffers[bufferView.buffer]?.resolvedBuffer;\n            if (!bufferData)\n                return;\n            const offset = bufferView.byteOffset ?? 0;\n            const bytes = bufferData.subarray(offset, offset + bufferView.byteLength);\n            try {\n                const imageSource = new ImageSource(bytes, format);\n                if (this._system.supportsCreateImageBitmap)\n                    image.resolvedImage = await imageBitmapFromImageSource(imageSource);\n                else\n                    image.resolvedImage = await imageElementFromImageSource(imageSource);\n            }\n            catch (_) {\n                //\n            }\n            return;\n        }\n        const url = undefined !== image.uri ? this.resolveUrl(image.uri) : undefined;\n        if (undefined !== url)\n            image.resolvedImage = await tryImageElementFromUrl(url);\n    }\n    /** Exposed strictly for testing. */\n    getTextureType(sampler) {\n        // ###TODO: RenderTexture currently does not support different wrapping behavior for U vs V, nor does it support mirrored repeat.\n        let wrapS = sampler?.wrapS;\n        let wrapT = sampler?.wrapT;\n        if (undefined === wrapS && undefined === wrapT)\n            wrapS = wrapT = this.defaultWrapMode;\n        if (GltfWrapMode.ClampToEdge === wrapS || GltfWrapMode.ClampToEdge === wrapT)\n            return RenderTexture.Type.TileSection;\n        return RenderTexture.Type.Normal;\n    }\n    resolveTexture(textureId, isTransparent) {\n        const texture = this._textures[textureId];\n        if (!texture || undefined === texture.source)\n            return false;\n        const image = this._images[texture.source]?.resolvedImage;\n        if (!image)\n            return false;\n        const samplerId = texture.sampler;\n        const sampler = undefined !== samplerId ? this._samplers[samplerId] : undefined;\n        const textureType = this.getTextureType(sampler);\n        const renderTexture = this._system.createTexture({\n            type: textureType,\n            image: {\n                source: image,\n                transparency: isTransparent ? TextureTransparency.Mixed : TextureTransparency.Opaque,\n            },\n        });\n        return renderTexture ?? false;\n    }\n    findTextureMapping(id, isTransparent, normalMapId) {\n        if (undefined === id && undefined === normalMapId)\n            return undefined;\n        let texture;\n        if (undefined !== id) {\n            texture = this._resolvedTextures.get({ id, isTransparent });\n            if (undefined === texture)\n                this._resolvedTextures.set({ id, isTransparent }, texture = this.resolveTexture(id, isTransparent));\n        }\n        let normalMap;\n        if (undefined !== normalMapId) {\n            normalMap = this._resolvedTextures.get({ id: normalMapId, isTransparent: false });\n            if (undefined === normalMap)\n                this._resolvedTextures.set({ id: normalMapId, isTransparent: false }, normalMap = this.resolveTexture(normalMapId, false));\n        }\n        let nMap;\n        if (normalMap) {\n            const greenUp = true;\n            if (texture) {\n                nMap = {\n                    normalMap,\n                    greenUp,\n                };\n            }\n            else {\n                texture = normalMap;\n                nMap = { greenUp };\n            }\n        }\n        if (!texture)\n            return undefined;\n        const textureMapping = new TextureMapping(texture, new TextureMapping.Params());\n        textureMapping.normalMapParams = nMap;\n        return textureMapping;\n    }\n}\n/** Produce a [[RenderGraphic]] from a [glTF](https://www.khronos.org/gltf/) asset suitable for use in [view decorations]($docs/learning/frontend/ViewDecorations).\n * @returns a graphic produced from the glTF asset's default scene, or `undefined` if a graphic could not be produced from the asset.\n * @note Support for the full [glTF 2.0 specification](https://www.khronos.org/registry/glTF/specs/2.0/glTF-2.0.html) is currently a work in progress.\n * If a particular glTF asset fails to load and/or display properly, please\n * [submit an issue](https://github.com/iTwin/itwinjs-core/issues).\n * @see [Example decorator]($docs/learning/frontend/ViewDecorations#gltf-decorations) for an example of a decorator that reads and displays a glTF asset.\n * @see [[readGltf]] to obtain more information about the glTF model.\n * @public\n * @extensions\n */\nexport async function readGltfGraphics(args) {\n    const result = await readGltf(args);\n    return result?.graphic;\n}\n/** Produce a [[RenderGraphic]] from a [glTF](https://www.khronos.org/gltf/) asset suitable for use in [view decorations]($docs/learning/frontend/ViewDecorations).\n * @returns a graphic produced from the glTF asset's default scene, or `undefined` if a graphic could not be produced from the asset.\n * The returned graphic also includes the bounding boxes of the glTF model in world and local coordiantes.\n * @note Support for the full [glTF 2.0 specification](https://www.khronos.org/registry/glTF/specs/2.0/glTF-2.0.html) is currently a work in progress.\n * If a particular glTF asset fails to load and/or display properly, please\n * [submit an issue](https://github.com/iTwin/itwinjs-core/issues).\n * @see [Example decorator]($docs/learning/frontend/ViewDecorations#gltf-decorations) for an example of a decorator that reads and displays a glTF asset.\n * @public\n */\nexport async function readGltf(args) {\n    const baseUrl = typeof args.baseUrl === \"string\" ? new URL(args.baseUrl) : args.baseUrl;\n    const props = GltfReaderProps.create(args.gltf, true, baseUrl); // glTF supports exactly one coordinate system with y axis up.\n    const reader = props ? new GltfGraphicsReader(props, args) : undefined;\n    if (!reader)\n        return undefined;\n    const result = await reader.read();\n    if (!result.graphic)\n        return undefined;\n    assert(result.contentRange !== undefined, \"readGltf always computes content range\");\n    assert(result.range !== undefined, \"readGltf always computes world range\");\n    return {\n        graphic: result.graphic,\n        localBoundingBox: result.contentRange ?? Range3d.createNull(),\n        boundingBox: result.range ?? Range3d.createNull(),\n    };\n}\n/** Implements [[readGltfGraphics]]. Exported strictly for tests.\n * @internal\n */\nexport class GltfGraphicsReader extends GltfReader {\n    constructor(props, args) {\n        super({\n            props,\n            iModel: args.iModel,\n            vertexTableRequired: true,\n        });\n        this._contentRange = args.contentRange;\n        this._transform = args.transform;\n        this._isLeaf = true !== args.hasChildren;\n        this.binaryData = props.binaryData;\n        const pickableId = args.pickableOptions?.id;\n        if (pickableId) {\n            this._featureTable = new FeatureTable(1, args.pickableOptions?.modelId ?? pickableId, BatchType.Primary);\n            this._featureTable.insert(new Feature(pickableId));\n        }\n    }\n    async read() {\n        await this.resolveResources();\n        return this.readGltfAndCreateGraphics(this._isLeaf, this._featureTable, this._contentRange, this._transform);\n    }\n    get nodes() { return this._nodes; }\n    get scenes() { return this._glTF.scenes ?? emptyDict; }\n    get sceneNodes() { return this._sceneNodes; }\n    get textures() { return this._textures; }\n}\n//# sourceMappingURL=GltfReader.js.map",
      "start": 1693508121609,
      "end": 1693508121742,
      "sourcemaps": null
    },
    {
      "name": "vite:build-import-analysis",
      "result": "import { __vitePreload } from \"\u0000vite/preload-helper\";/*---------------------------------------------------------------------------------------------\n* Copyright (c) Bentley Systems, Incorporated. All rights reserved.\n* See LICENSE.md in the project root for license terms and full copyright notice.\n*--------------------------------------------------------------------------------------------*/\n/** @packageDocumentation\n * @module Tiles\n */\nimport { assert, ByteStream, compareBooleans, compareNumbers, compareStrings, Dictionary, JsonUtils, Logger, utf8ToString, } from \"@itwin/core-bentley\";\nimport { Angle, IndexedPolyface, Matrix3d, Point2d, Point3d, Point4d, Range2d, Range3d, Transform, Vector3d, } from \"@itwin/core-geometry\";\nimport { BatchType, ColorDef, Feature, FeatureIndex, FeatureIndexType, FeatureTable, FillFlags, GlbHeader, ImageSource, LinePixels, MeshEdge, MeshEdges, MeshPolyline, OctEncodedNormal, PackedFeatureTable, QParams2d, QParams3d, QPoint2dList, QPoint3dList, Quantization, RenderTexture, TextureMapping, TextureTransparency, TileFormat, TileReadStatus, } from \"@itwin/core-common\";\nimport { IModelApp } from \"../IModelApp\";\nimport { GraphicBranch } from \"../render/GraphicBranch\";\nimport { RealityMeshParams } from \"../render/RealityMeshParams\";\nimport { Mesh } from \"../render/primitives/mesh/MeshPrimitives\";\nimport { Triangle } from \"../render/primitives/Primitives\";\nimport { DisplayParams } from \"../common/render/primitives/DisplayParams\";\nimport { FrontendLoggerCategory } from \"../common/FrontendLoggerCategory\";\nimport { getImageSourceFormatForMimeType, imageBitmapFromImageSource, imageElementFromImageSource, tryImageElementFromUrl } from \"../common/ImageUtil\";\nimport { MeshPrimitiveType } from \"../common/render/primitives/MeshPrimitive\";\nimport { getGltfNodeMeshIds, GltfDataType, gltfDictionaryIterator, GltfMeshMode, GltfTechniqueState, GltfWrapMode, isGltf1Material, traverseGltfNodes, } from \"../common/gltf/GltfSchema\";\n/**\n * A chunk of binary data exposed as a typed array.\n * The count member indicates how many elements exist. This may be less than this.buffer.length due to padding added to the\n * binary stream to ensure correct alignment.\n * @internal\n */\nexport class GltfBufferData {\n    constructor(buffer, count) {\n        this.buffer = buffer;\n        this.count = count;\n    }\n    /**\n     * Create a GltfBufferData of the desired type. The actual type may differ from the desired type - for example, small 32-bit integers\n     * may be represented as 8-bit or 16-bit integers instead.\n     * If the actual data type is not convertible to the desired type, this function returns undefined.\n     */\n    static create(bytes, actualType, expectedType, count) {\n        if (expectedType !== actualType) {\n            // Some data is stored in smaller data types to save space if no values exceed the maximum of the smaller type.\n            switch (expectedType) {\n                case GltfDataType.Float:\n                case GltfDataType.UnsignedByte:\n                    return undefined;\n                case GltfDataType.UnsignedShort:\n                    if (GltfDataType.UnsignedByte !== actualType)\n                        return undefined;\n                    break;\n                case GltfDataType.UInt32:\n                    if (GltfDataType.UnsignedByte !== actualType && GltfDataType.UnsignedShort !== actualType)\n                        return undefined;\n                    break;\n            }\n        }\n        const data = this.createDataBuffer(bytes, actualType);\n        return undefined !== data ? new GltfBufferData(data, count) : undefined;\n    }\n    static createDataBuffer(bytes, actualType) {\n        // NB: Endianness of typed array data is determined by the 'platform byte order'. Actual data is always little-endian.\n        // We are assuming little-endian platform. If we find a big-endian platform, we'll need to use a DataView instead.\n        switch (actualType) {\n            case GltfDataType.UnsignedByte:\n                return bytes;\n            case GltfDataType.UnsignedShort:\n                return new Uint16Array(bytes.buffer, bytes.byteOffset, bytes.byteLength / 2);\n            case GltfDataType.UInt32:\n                return new Uint32Array(bytes.buffer, bytes.byteOffset, bytes.byteLength / 4);\n            case GltfDataType.Float:\n                return new Float32Array(bytes.buffer, bytes.byteOffset, bytes.byteLength / 4);\n            default:\n                return undefined;\n        }\n    }\n}\n/**\n * A view of a chunk of glTF binary data containing an array of elements of a specific data type.\n * The count member indicates how many elements exist; this may be smaller than this.data.length.\n * The count member may also indicate the number of elements of a type containing more than one value of the\n * underlying type. For example, a buffer of 4 32-bit floating point 'vec2' elements will have a count of 4,\n * but its data member will contain 8 32-bit floating point values (2 per vec2).\n * The accessor member may contain additional JSON data specific to a particular buffer.\n * @internal\n */\nclass GltfBufferView {\n    get byteLength() { return this.data.length; }\n    constructor(data, count, type, accessor, stride) {\n        this.data = data;\n        this.count = count;\n        this.type = type;\n        this.accessor = accessor;\n        this.stride = stride;\n    }\n    toBufferData(desiredType) {\n        return GltfBufferData.create(this.data, this.type, desiredType, this.count);\n    }\n}\n/** Data required for creating a [[GltfReader]] capable of deserializing [glTF](https://www.khronos.org/gltf/).\n * @internal\n */\nexport class GltfReaderProps {\n    constructor(glTF, version, yAxisUp, binaryData, baseUrl) {\n        this.version = version;\n        this.glTF = glTF;\n        this.binaryData = binaryData;\n        this.yAxisUp = yAxisUp;\n        this.baseUrl = baseUrl;\n    }\n    /** Attempt to construct a new GltfReaderProps from the binary data beginning at the supplied stream's current read position. */\n    static create(source, yAxisUp = false, baseUrl) {\n        let version;\n        let json;\n        let binaryData;\n        if (source instanceof Uint8Array) {\n            // It may be JSON - check for magic indicating glb.\n            const buffer = ByteStream.fromUint8Array(source);\n            if (TileFormat.Gltf !== buffer.readUint32()) {\n                try {\n                    const utf8Json = utf8ToString(source);\n                    if (!utf8Json)\n                        return undefined;\n                    json = JSON.parse(utf8Json);\n                    version = 2;\n                }\n                catch (_) {\n                    return undefined;\n                }\n            }\n            else {\n                buffer.reset();\n                const header = new GlbHeader(buffer);\n                if (!header.isValid)\n                    return undefined;\n                version = header.version;\n                if (header.binaryChunk)\n                    binaryData = new Uint8Array(source.buffer, source.byteOffset + header.binaryChunk.offset, header.binaryChunk.length);\n                try {\n                    const jsonBytes = new Uint8Array(source.buffer, source.byteOffset + header.jsonChunk.offset, header.jsonChunk.length);\n                    const jsonStr = utf8ToString(jsonBytes);\n                    if (undefined === jsonStr)\n                        return undefined;\n                    json = JSON.parse(jsonStr);\n                }\n                catch (_) {\n                    return undefined;\n                }\n            }\n        }\n        else {\n            version = 2; // ###TODO verify against source.asset?.version\n            json = source;\n        }\n        // asset is required in glTF 2, optional in glTF 1\n        const asset = JsonUtils.asObject(json.asset);\n        if (version === 2 && !asset)\n            return undefined;\n        const glTF = {\n            asset,\n            scene: JsonUtils.asString(json.scene),\n            extensions: JsonUtils.asObject(json.extensions),\n            extensionsUsed: JsonUtils.asArray(json.extensionsUsed),\n            extensionsRequired: JsonUtils.asArray(json.extensionsRequired),\n            accessors: JsonUtils.asObject(json.accessors),\n            buffers: JsonUtils.asObject(json.buffers),\n            bufferViews: JsonUtils.asObject(json.bufferViews),\n            images: JsonUtils.asObject(json.images),\n            materials: JsonUtils.asObject(json.materials),\n            meshes: JsonUtils.asObject(json.meshes),\n            nodes: JsonUtils.asObject(json.nodes),\n            samplers: JsonUtils.asObject(json.samplers),\n            scenes: JsonUtils.asObject(json.scenes),\n            textures: JsonUtils.asObject(json.textures),\n            techniques: JsonUtils.asObject(json.techniques),\n        };\n        return glTF.meshes ? new GltfReaderProps(glTF, version, yAxisUp, binaryData, baseUrl) : undefined;\n    }\n}\n/** The GltfMeshData contains the raw GLTF mesh data. If the data is suitable to create a [[RealityMesh]] directly, basically in the quantized format produced by\n  * ContextCapture, then a RealityMesh is created directly from this data. Otherwise, the mesh primitive is populated from the raw data and a MeshPrimitive\n  * is generated. The MeshPrimitve path is much less efficient but should be rarely used.\n  *\n  * @internal\n  */\nexport class GltfMeshData {\n    constructor(props) {\n        this.type = \"mesh\";\n        this.primitive = props;\n    }\n}\nconst emptyDict = {};\nfunction colorFromJson(values) {\n    return ColorDef.from(values[0] * 255, values[1] * 255, values[2] * 255, (1.0 - values[3]) * 255);\n}\nfunction colorFromMaterial(material, isTransparent) {\n    let color = ColorDef.white;\n    if (isGltf1Material(material)) {\n        if (material.values?.color && Array.isArray(material.values.color))\n            color = colorFromJson(material.values.color);\n    }\n    else if (material.extensions?.KHR_techniques_webgl?.values?.u_color) {\n        color = colorFromJson(material.extensions.KHR_techniques_webgl.values.u_color);\n    }\n    else if (material.pbrMetallicRoughness?.baseColorFactor) {\n        color = colorFromJson(material.pbrMetallicRoughness.baseColorFactor);\n    }\n    // SPEC: Opaque materials ignore any alpha channel.\n    if (!isTransparent)\n        color = color.withTransparency(0);\n    return color;\n}\nclass TransformStack {\n    constructor(transform) {\n        this._stack = [];\n        if (transform)\n            this._stack.push(transform);\n    }\n    get transform() {\n        return this._stack.length > 0 ? this._stack[this._stack.length - 1] : undefined;\n    }\n    get isEmpty() {\n        return 0 === this._stack.length;\n    }\n    push(node) {\n        let nodeTransform;\n        if (node.matrix) {\n            const origin = Point3d.create(node.matrix[12], node.matrix[13], node.matrix[14]);\n            const matrix = Matrix3d.createRowValues(node.matrix[0], node.matrix[4], node.matrix[8], node.matrix[1], node.matrix[5], node.matrix[9], node.matrix[2], node.matrix[6], node.matrix[10]);\n            nodeTransform = Transform.createOriginAndMatrix(origin, matrix);\n        }\n        else if (node.rotation || node.scale || node.translation) {\n            // SPEC: To compose the local transformation matrix, TRS properties MUST be converted to matrices and postmultiplied in the T * R * S order;\n            // first the scale is applied to the vertices, then the rotation, and then the translation.\n            const scale = Transform.createRefs(undefined, node.scale ? Matrix3d.createScale(node.scale[0], node.scale[1], node.scale[2]) : Matrix3d.identity);\n            const rot = Transform.createRefs(undefined, node.rotation ? Matrix3d.createFromQuaternion(Point4d.create(node.rotation[0], node.rotation[1], node.rotation[2], node.rotation[3])) : Matrix3d.identity);\n            rot.matrix.transposeInPlace(); // See comment on Matrix3d.createFromQuaternion\n            const trans = Transform.createTranslation(node.translation ? new Point3d(node.translation[0], node.translation[1], node.translation[2]) : Point3d.createZero());\n            nodeTransform = scale.multiplyTransformTransform(rot);\n            trans.multiplyTransformTransform(nodeTransform, nodeTransform);\n        }\n        const top = this.transform;\n        if (!top)\n            this._stack.push(nodeTransform);\n        else\n            this._stack.push(nodeTransform ? top.multiplyTransformTransform(nodeTransform) : top);\n    }\n    pop() {\n        assert(this._stack.length > 0);\n        this._stack.pop();\n    }\n}\nfunction compareTextureKeys(lhs, rhs) {\n    const cmp = compareBooleans(lhs.isTransparent, rhs.isTransparent);\n    if (0 !== cmp)\n        return cmp;\n    assert(typeof lhs.id === typeof rhs.id);\n    if (\"string\" === typeof lhs.id) {\n        assert(\"string\" === typeof rhs.id);\n        return compareStrings(lhs.id, rhs.id);\n    }\n    assert(\"number\" === typeof lhs.id && \"number\" === typeof rhs.id);\n    return compareNumbers(lhs.id, rhs.id);\n}\n/** Deserializes [glTF](https://www.khronos.org/gltf/).\n * @internal\n */\nexport class GltfReader {\n    get _nodes() { return this._glTF.nodes ?? emptyDict; }\n    get _meshes() { return this._glTF.meshes ?? emptyDict; }\n    get _accessors() { return this._glTF.accessors ?? emptyDict; }\n    get _bufferViews() { return this._glTF.bufferViews ?? emptyDict; }\n    get _materials() { return this._glTF.materials ?? emptyDict; }\n    get _samplers() { return this._glTF.samplers ?? emptyDict; }\n    get _textures() { return this._glTF.textures ?? emptyDict; }\n    get _images() { return this._glTF.images ?? emptyDict; }\n    get _buffers() { return this._glTF.buffers ?? emptyDict; }\n    get _isCanceled() { return undefined !== this._canceled && this._canceled(this); }\n    get _isVolumeClassifier() { return BatchType.VolumeClassifier === this._type; }\n    /** Traverse the nodes specified by their Ids, recursing into their child nodes.\n     * @param nodeIds The Ids of the nodes to traverse.\n     * @throws Error if a node appears more than once during traversal\n     */\n    traverseNodes(nodeIds) {\n        return traverseGltfNodes(nodeIds, this._nodes, new Set());\n    }\n    /** Traverse the nodes specified by their scene, recursing into their child nodes.\n     * @throws Error if a node appears more than once during traversal\n     */\n    traverseScene() {\n        return this.traverseNodes(this._sceneNodes);\n    }\n    getTileTransform(transformToRoot, pseudoRtcBias) {\n        let transform;\n        if (this._returnToCenter || pseudoRtcBias || this._yAxisUp || transformToRoot) {\n            if (this._returnToCenter)\n                transform = Transform.createTranslation(this._returnToCenter.clone());\n            else if (pseudoRtcBias)\n                transform = Transform.createTranslationXYZ(pseudoRtcBias.x, pseudoRtcBias.y, pseudoRtcBias.z);\n            else\n                transform = Transform.createIdentity();\n            if (this._yAxisUp)\n                transform = transform.multiplyTransformMatrix3d(Matrix3d.createRotationAroundVector(Vector3d.create(1.0, 0.0, 0.0), Angle.createRadians(Angle.piOver2Radians)));\n            if (transformToRoot)\n                transform = transformToRoot.multiplyTransformTransform(transform);\n        }\n        return transform;\n    }\n    readGltfAndCreateGraphics(isLeaf, featureTable, contentRange, transformToRoot, pseudoRtcBias, instances) {\n        if (this._isCanceled)\n            return { readStatus: TileReadStatus.Canceled, isLeaf };\n        // If contentRange was not supplied, we will compute it as we read the meshes.\n        if (!contentRange)\n            this._computedContentRange = contentRange = Range3d.createNull();\n        else\n            this._computedContentRange = undefined;\n        // ###TODO this looks like a hack? Why does it assume the first node's transform is special, or that the transform will be specified as a matrix instead of translation+rot+scale?\n        if (this._returnToCenter || this._nodes[0]?.matrix || (pseudoRtcBias && pseudoRtcBias.magnitude() < 1.0E5))\n            pseudoRtcBias = undefined;\n        const transformStack = new TransformStack();\n        const renderGraphicList = [];\n        let readStatus = TileReadStatus.InvalidTileData;\n        for (const nodeKey of this._sceneNodes) {\n            assert(transformStack.isEmpty);\n            const node = this._nodes[nodeKey];\n            if (node && TileReadStatus.Success !== (readStatus = this.readNodeAndCreateGraphics(renderGraphicList, node, featureTable, transformStack, instances, pseudoRtcBias)))\n                return { readStatus, isLeaf };\n        }\n        if (0 === renderGraphicList.length)\n            return { readStatus: TileReadStatus.InvalidTileData, isLeaf };\n        let renderGraphic;\n        if (1 === renderGraphicList.length)\n            renderGraphic = renderGraphicList[0];\n        else\n            renderGraphic = this._system.createGraphicList(renderGraphicList);\n        const transform = this.getTileTransform(transformToRoot, pseudoRtcBias);\n        let range = contentRange;\n        const invTransform = transform?.inverse();\n        if (invTransform)\n            range = invTransform.multiplyRange(contentRange);\n        if (featureTable)\n            renderGraphic = this._system.createBatch(renderGraphic, PackedFeatureTable.pack(featureTable), range);\n        if (transform) {\n            const branch = new GraphicBranch(true);\n            branch.add(renderGraphic);\n            renderGraphic = this._system.createBranch(branch, transform);\n        }\n        return {\n            readStatus,\n            isLeaf,\n            contentRange,\n            range,\n            graphic: renderGraphic,\n            containsPointCloud: this._containsPointCloud,\n        };\n    }\n    readGltfAndCreateGeometry(transformToRoot, needNormals = false, needParams = false) {\n        const transformStack = new TransformStack(this.getTileTransform(transformToRoot));\n        const polyfaces = [];\n        for (const nodeKey of this._sceneNodes) {\n            const node = this._nodes[nodeKey];\n            if (node)\n                this.readNodeAndCreatePolyfaces(polyfaces, node, transformStack, needNormals, needParams);\n        }\n        return { polyfaces };\n    }\n    graphicFromMeshData(gltfMesh, instances) {\n        if (\"pointcloud\" === gltfMesh.type)\n            return this._system.createPointCloud(gltfMesh, this._iModel);\n        if (!gltfMesh.points || !gltfMesh.pointRange)\n            return gltfMesh.primitive.getGraphics(this._system, instances);\n        const realityMeshPrimitive = (this._vertexTableRequired || instances) ? undefined : RealityMeshParams.fromGltfMesh(gltfMesh);\n        if (realityMeshPrimitive) {\n            const realityMesh = this._system.createRealityMesh(realityMeshPrimitive);\n            if (realityMesh)\n                return realityMesh;\n        }\n        const mesh = gltfMesh.primitive;\n        const pointCount = gltfMesh.points.length / 3;\n        assert(mesh.points instanceof QPoint3dList);\n        mesh.points.fromTypedArray(gltfMesh.pointRange, gltfMesh.points);\n        if (mesh.triangles && gltfMesh.indices)\n            mesh.triangles.addFromTypedArray(gltfMesh.indices);\n        if (gltfMesh.uvs && gltfMesh.uvRange && gltfMesh.uvQParams) {\n            /** This is ugly and inefficient... unnecessary if Mesh stored uvs as QPoint2dList */\n            for (let i = 0, j = 0; i < pointCount; i++)\n                mesh.uvParams.push(gltfMesh.uvQParams.unquantize(gltfMesh.uvs[j++], gltfMesh.uvs[j++]));\n        }\n        if (gltfMesh.normals)\n            for (const normal of gltfMesh.normals)\n                mesh.normals.push(new OctEncodedNormal(normal));\n        return mesh.getGraphics(this._system, instances);\n    }\n    readNodeAndCreateGraphics(renderGraphicList, node, featureTable, transformStack, instances, pseudoRtcBias) {\n        if (undefined === node)\n            return TileReadStatus.InvalidTileData;\n        // IMPORTANT: Do not return without popping this node from the stack.\n        transformStack.push(node);\n        const thisTransform = transformStack.transform;\n        /**\n         * This is a workaround for tiles generated by\n         * context capture which have a large offset from the tileset origin that exceeds the\n         * capacity of 32 bit integers. It is essentially an ad hoc RTC applied at read time only if the tile is far from the\n         * origin and there is no RTC supplied either with the B3DM of the GLTF.\n         * as the vertices are supplied in a quantized format, applying the RTC bias to\n         * quantization origin will make these tiles work correctly.\n         */\n        let thisBias;\n        if (undefined !== pseudoRtcBias)\n            thisBias = (undefined === thisTransform) ? pseudoRtcBias : thisTransform.matrix.multiplyInverse(pseudoRtcBias);\n        for (const meshKey of getGltfNodeMeshIds(node)) {\n            const nodeMesh = this._meshes[meshKey];\n            if (nodeMesh?.primitives) {\n                const meshes = this.readMeshPrimitives(node, featureTable, thisTransform, thisBias);\n                let renderGraphic;\n                if (0 !== meshes.length) {\n                    if (1 === meshes.length) {\n                        renderGraphic = this.graphicFromMeshData(meshes[0], instances);\n                    }\n                    else {\n                        const thisList = [];\n                        for (const mesh of meshes) {\n                            renderGraphic = this.graphicFromMeshData(mesh, instances);\n                            if (undefined !== renderGraphic)\n                                thisList.push(renderGraphic);\n                        }\n                        if (0 !== thisList.length)\n                            renderGraphic = this._system.createGraphicList(thisList);\n                    }\n                    if (renderGraphic) {\n                        if (thisTransform && !thisTransform.isIdentity) {\n                            const branch = new GraphicBranch(true);\n                            branch.add(renderGraphic);\n                            renderGraphic = this._system.createBranch(branch, thisTransform);\n                        }\n                        renderGraphicList.push(renderGraphic);\n                    }\n                }\n            }\n        }\n        if (node.children) {\n            for (const childId of node.children) {\n                const child = this._nodes[childId];\n                if (child)\n                    this.readNodeAndCreateGraphics(renderGraphicList, child, featureTable, transformStack, instances);\n            }\n        }\n        transformStack.pop();\n        return TileReadStatus.Success;\n    }\n    readNodeAndCreatePolyfaces(polyfaces, node, transformStack, needNormals, needParams) {\n        // IMPORTANT: Do not return without popping this node from the stack.\n        transformStack.push(node);\n        const meshes = this.readMeshPrimitives(node);\n        for (const mesh of meshes) {\n            if (mesh.type === \"mesh\") {\n                const polyface = this.polyfaceFromGltfMesh(mesh, transformStack.transform, needNormals, needParams);\n                if (polyface)\n                    polyfaces.push(polyface);\n            }\n        }\n        if (node.children) {\n            for (const childId of node.children) {\n                const child = this._nodes[childId];\n                if (child)\n                    this.readNodeAndCreatePolyfaces(polyfaces, child, transformStack, needNormals, needParams);\n            }\n        }\n    }\n    polyfaceFromGltfMesh(mesh, transform, needNormals, needParams) {\n        if (!mesh.pointQParams || !mesh.points || !mesh.indices)\n            return undefined;\n        const { points, pointQParams, normals, uvs, uvQParams, indices } = mesh;\n        const includeNormals = needNormals && undefined !== normals;\n        const includeParams = needParams && undefined !== uvQParams && undefined !== uvs;\n        const polyface = IndexedPolyface.create(includeNormals, includeParams);\n        for (let i = 0; i < points.length;) {\n            const point = pointQParams.unquantize(points[i++], points[i++], points[i++]);\n            if (transform)\n                transform.multiplyPoint3d(point, point);\n            polyface.addPoint(point);\n        }\n        if (includeNormals && normals)\n            for (let i = 0; i < normals.length;)\n                polyface.addNormal(OctEncodedNormal.decodeValue(normals[i++]));\n        if (includeParams && uvs && uvQParams)\n            for (let i = 0; i < uvs.length;)\n                polyface.addParam(uvQParams.unquantize(uvs[i++], uvs[i++]));\n        let j = 0;\n        for (const index of indices) {\n            polyface.addPointIndex(index);\n            if (includeNormals)\n                polyface.addNormalIndex(index);\n            if (includeParams)\n                polyface.addParamIndex(index);\n            if (0 === (++j % 3))\n                polyface.terminateFacet();\n        }\n        return polyface;\n    }\n    // ###TODO what is the actual type of `json`?\n    getBufferView(json, accessorName) {\n        try {\n            const accessorValue = JsonUtils.asString(json[accessorName]);\n            const accessor = accessorValue ? this._accessors[accessorValue] : undefined;\n            if (!accessor)\n                return undefined;\n            const bufferViewAccessorValue = accessor.bufferView;\n            const bufferView = undefined !== bufferViewAccessorValue ? this._bufferViews[bufferViewAccessorValue] : undefined;\n            if (!bufferView || undefined === bufferView.buffer)\n                return undefined;\n            const buffer = this._buffers[bufferView.buffer];\n            const bufferData = buffer?.resolvedBuffer;\n            if (!bufferData)\n                return undefined;\n            const type = accessor.componentType;\n            let dataSize = 0;\n            switch (type) {\n                case GltfDataType.UnsignedByte:\n                    dataSize = 1;\n                    break;\n                case GltfDataType.UnsignedShort:\n                    dataSize = 2;\n                    break;\n                case GltfDataType.UInt32:\n                case GltfDataType.Float:\n                    dataSize = 4;\n                    break;\n                default:\n                    return undefined;\n            }\n            let componentCount = 1;\n            switch (accessor.type) {\n                case \"VEC4\":\n                    componentCount = 4;\n                    break;\n                case \"VEC3\":\n                    componentCount = 3;\n                    break;\n                case \"VEC2\":\n                    componentCount = 2;\n                    break;\n            }\n            const byteStride = bufferView.byteStride ? bufferView.byteStride : componentCount * dataSize;\n            const offset = ((bufferView && bufferView.byteOffset) ? bufferView.byteOffset : 0) + (accessor.byteOffset ? accessor.byteOffset : 0);\n            const length = byteStride * accessor.count;\n            // If the data is misaligned (Scalable mesh tile publisher) use slice to copy -- else use subarray.\n            const aligned = 0 === (bufferData.byteOffset + offset) % dataSize;\n            const bytes = aligned ? bufferData.subarray(offset, offset + length) : bufferData.slice(offset, offset + length);\n            return new GltfBufferView(bytes, accessor.count, type, accessor, byteStride / dataSize);\n        }\n        catch (e) {\n            return undefined;\n        }\n    }\n    readBufferData32(json, accessorName) { return this.readBufferData(json, accessorName, GltfDataType.UInt32); }\n    readBufferData16(json, accessorName) { return this.readBufferData(json, accessorName, GltfDataType.UnsignedShort); }\n    readBufferData8(json, accessorName) { return this.readBufferData(json, accessorName, GltfDataType.UnsignedByte); }\n    readBufferDataFloat(json, accessorName) { return this.readBufferData(json, accessorName, GltfDataType.Float); }\n    constructor(args) {\n        this._resolvedTextures = new Dictionary((lhs, rhs) => compareTextureKeys(lhs, rhs));\n        this._dracoMeshes = new Map();\n        this._containsPointCloud = false;\n        /** The glTF spec says that if GltfSampler.wrapS/T are omitted, they default to Repeat.\n         * However, the reality data service serves tiles that lack any wrapS/T property, and we want those clamped to edge, not repeated.\n         * (We also don't want to produce mip-maps for them, which is determined indirectly from the wrap mode).\n         * Allow the default to be optionally overridden.\n         */\n        this.defaultWrapMode = GltfWrapMode.Repeat;\n        this._glTF = args.props.glTF;\n        this._version = args.props.version;\n        this._yAxisUp = args.props.yAxisUp;\n        this._baseUrl = args.props.baseUrl;\n        const rtcCenter = args.props.glTF.extensions?.CESIUM_RTC?.center;\n        if (rtcCenter && 3 === rtcCenter.length)\n            if (0 !== rtcCenter[0] || 0 !== rtcCenter[1] || 0 !== rtcCenter[2])\n                this._returnToCenter = Point3d.fromJSON(rtcCenter);\n        this._iModel = args.iModel;\n        this._is3d = true !== args.is2d;\n        this._system = args.system ?? IModelApp.renderSystem;\n        this._type = args.type ?? BatchType.Primary;\n        this._canceled = args.shouldAbort;\n        this._deduplicateVertices = args.deduplicateVertices ?? false;\n        this._vertexTableRequired = args.vertexTableRequired ?? false;\n        const binaryData = args.props.binaryData;\n        if (binaryData) {\n            const buffer = this._buffers[this._version === 2 ? 0 : \"binary_glTF\"];\n            if (buffer && undefined === buffer.uri)\n                buffer.resolvedBuffer = binaryData;\n        }\n        // The original implementation of GltfReader would process and produce graphics for every node in glTF.nodes.\n        // What it's *supposed* to do is process the nodes in glTF.scenes[glTF.scene].nodes\n        // Some nodes may not be referenced by the configured scene, or only indirectly via GltfNode.children.\n        // Perhaps some faulty tiles existed that didn't define their scenes properly?\n        let sceneNodes;\n        if (this._glTF.scenes && undefined !== this._glTF.scene)\n            sceneNodes = this._glTF.scenes[this._glTF.scene]?.nodes;\n        if (!sceneNodes)\n            sceneNodes = Object.keys(this._nodes);\n        this._sceneNodes = sceneNodes;\n    }\n    readBufferData(json, accessorName, type) {\n        const view = this.getBufferView(json, accessorName);\n        return undefined !== view ? view.toBufferData(type) : undefined;\n    }\n    readFeatureIndices(_json) { return undefined; }\n    extractId(value) {\n        switch (typeof value) {\n            case \"string\":\n                return value;\n            case \"number\":\n                return value.toString();\n            default:\n                return undefined;\n        }\n    }\n    extractTextureId(material) {\n        if (typeof material !== \"object\")\n            return undefined;\n        // Bimium's shader value...almost certainly obsolete at this point.\n        if (isGltf1Material(material))\n            return material.diffuse ?? this.extractId(material.values?.tex);\n        // KHR_techniques_webgl extension\n        const techniques = this._glTF.extensions?.KHR_techniques_webgl?.techniques;\n        const ext = Array.isArray(techniques) ? material.extensions?.KHR_techniques_webgl : undefined;\n        if (techniques && undefined !== ext && typeof (ext.values) === \"object\") {\n            const uniforms = typeof ext.technique === \"number\" ? techniques[ext.technique].uniforms : undefined;\n            if (typeof uniforms === \"object\") {\n                for (const uniformName of Object.keys(uniforms)) {\n                    const uniform = uniforms[uniformName];\n                    if (typeof uniform === \"object\" && uniform.type === GltfDataType.Sampler2d)\n                        return this.extractId(ext.values[uniformName]?.index);\n                }\n            }\n        }\n        const id = this.extractId(material.pbrMetallicRoughness?.baseColorTexture?.index);\n        return id ?? this.extractId(material.emissiveTexture?.index);\n    }\n    extractNormalMapId(material) {\n        if (typeof material !== \"object\")\n            return undefined;\n        if (isGltf1Material(material))\n            return undefined;\n        return this.extractId(material.normalTexture?.index);\n    }\n    isMaterialTransparent(material) {\n        if (isGltf1Material(material)) {\n            if (this._glTF.techniques && undefined !== material.technique) {\n                const technique = this._glTF.techniques[material.technique];\n                if (technique?.states?.enable?.some((state) => state === GltfTechniqueState.Blend))\n                    return true;\n            }\n            return false;\n        }\n        else {\n            // Default: OPAQUE.\n            // ###TODO support MASK. For now treat as opaque.\n            return \"BLEND\" === material.alphaMode;\n        }\n    }\n    createDisplayParams(material, hasBakedLighting) {\n        const isTransparent = this.isMaterialTransparent(material);\n        const textureId = this.extractTextureId(material);\n        const normalMapId = this.extractNormalMapId(material);\n        let textureMapping = (undefined !== textureId || undefined !== normalMapId) ? this.findTextureMapping(textureId, isTransparent, normalMapId) : undefined;\n        const color = colorFromMaterial(material, isTransparent);\n        let renderMaterial;\n        if (undefined !== textureMapping && undefined !== textureMapping.normalMapParams) {\n            const args = { diffuse: { color }, specular: { color: ColorDef.white }, textureMapping };\n            renderMaterial = IModelApp.renderSystem.createRenderMaterial(args);\n            // DisplayParams doesn't want a separate texture mapping if the material already has one.\n            textureMapping = undefined;\n        }\n        return new DisplayParams(DisplayParams.Type.Mesh, color, color, 1, LinePixels.Solid, FillFlags.Always, renderMaterial, undefined, hasBakedLighting, textureMapping);\n    }\n    readMeshPrimitives(node, featureTable, thisTransform, thisBias) {\n        const meshes = [];\n        for (const meshKey of getGltfNodeMeshIds(node)) {\n            const nodeMesh = this._meshes[meshKey];\n            if (nodeMesh?.primitives) {\n                for (const primitive of nodeMesh.primitives) {\n                    const mesh = this.readMeshPrimitive(primitive, featureTable, thisBias);\n                    if (mesh) {\n                        meshes.push(mesh);\n                        if (this._computedContentRange && mesh.pointRange) {\n                            const invTransform = thisTransform?.inverse();\n                            const meshRange = invTransform ? invTransform.multiplyRange(mesh.pointRange) : mesh.pointRange;\n                            this._computedContentRange.extendRange(meshRange);\n                        }\n                    }\n                }\n            }\n        }\n        return meshes;\n    }\n    readMeshPrimitive(primitive, featureTable, pseudoRtcBias) {\n        const meshMode = JsonUtils.asInt(primitive.mode, GltfMeshMode.Triangles);\n        if (meshMode === GltfMeshMode.Points /* && !this._vertexTableRequired */) {\n            const pointCloud = this.readPointCloud(primitive, undefined !== featureTable);\n            if (pointCloud)\n                return pointCloud;\n        }\n        const materialName = JsonUtils.asString(primitive.material);\n        const material = 0 < materialName.length ? this._materials[materialName] : {};\n        if (!material)\n            return undefined;\n        const hasBakedLighting = undefined === primitive.attributes.NORMAL || undefined !== material.extensions?.KHR_materials_unlit;\n        const displayParams = material ? this.createDisplayParams(material, hasBakedLighting) : undefined;\n        if (!displayParams)\n            return undefined;\n        let primitiveType = -1;\n        switch (meshMode) {\n            case GltfMeshMode.Lines:\n                primitiveType = MeshPrimitiveType.Polyline;\n                break;\n            case GltfMeshMode.Points:\n                primitiveType = MeshPrimitiveType.Point;\n                break;\n            case GltfMeshMode.Triangles:\n                primitiveType = MeshPrimitiveType.Mesh;\n                break;\n            default:\n                return undefined;\n        }\n        const isVolumeClassifier = this._isVolumeClassifier;\n        const meshPrimitive = Mesh.create({\n            displayParams,\n            features: featureTable,\n            type: primitiveType,\n            range: Range3d.createNull(),\n            is2d: !this._is3d,\n            isPlanar: false,\n            hasBakedLighting,\n            isVolumeClassifier,\n            quantizePositions: true,\n        });\n        const mesh = new GltfMeshData(meshPrimitive);\n        // ###TODO_GLTF: There can be more than one color attribute; COLOR_0 might not be the one we want.\n        if (!this.readColors(mesh, primitive.attributes, \"COLOR_0\")) {\n            // We don't have real colormap - just load material color.  This will be used if non-Bentley\n            // tile or fit the color table is uniform. For a non-Bentley, non-Uniform, we'll set the\n            // uv parameters to pick the colors out of the color map texture.\n            meshPrimitive.colorMap.insert(displayParams.fillColor.tbgr); // White...\n            // _COLORINDEX is an ancient holdover from glTF 1.0 and Bimium...unlikely to actually encounter it in the wild.\n            const colorIndices = this.readBufferData16(primitive.attributes, \"_COLORINDEX\");\n            if (undefined !== colorIndices && material) {\n                let texStep;\n                if (isGltf1Material(material))\n                    texStep = material.values?.texStep;\n                else\n                    texStep = material.extensions?.KHR_techniques_webgl?.values?.u_texStep;\n                if (texStep) {\n                    const uvParams = [];\n                    for (let i = 0; i < colorIndices.count; i++)\n                        uvParams.push(new Point2d(texStep[1] + texStep[0] * colorIndices.buffer[i], .5));\n                    const paramList = QPoint2dList.fromPoints(uvParams);\n                    mesh.uvs = paramList.toTypedArray();\n                    mesh.uvQParams = paramList.params;\n                }\n            }\n        }\n        const draco = primitive.extensions?.KHR_draco_mesh_compression;\n        if (draco)\n            return this.readDracoMeshPrimitive(mesh.primitive, draco) ? mesh : undefined;\n        this.readBatchTable(mesh.primitive, primitive);\n        if (mesh.primitive.features) {\n            const features = this.readPrimitiveFeatures(primitive);\n            if (features) {\n                if (features instanceof Feature)\n                    mesh.primitive.features.add(features, 1);\n                else\n                    mesh.primitive.features.setIndices(features);\n            }\n        }\n        if (!this.readVertices(mesh, primitive, pseudoRtcBias))\n            return undefined;\n        switch (primitiveType) {\n            case MeshPrimitiveType.Mesh: {\n                if (!this.readMeshIndices(mesh, primitive))\n                    return undefined;\n                if (!displayParams.ignoreLighting && !this.readNormals(mesh, primitive.attributes, \"NORMAL\"))\n                    return undefined;\n                if (!mesh.uvs) {\n                    let texCoordIndex = 0;\n                    if (!isGltf1Material(material) && undefined !== material.pbrMetallicRoughness?.baseColorTexture?.texCoord)\n                        texCoordIndex = JsonUtils.asInt(material.pbrMetallicRoughness.baseColorTexture.texCoord);\n                    this.readUVParams(mesh, primitive.attributes, `TEXCOORD_${texCoordIndex}`);\n                }\n                if (this._deduplicateVertices && !this.deduplicateVertices(mesh))\n                    return undefined;\n                break;\n            }\n            case MeshPrimitiveType.Polyline:\n            case MeshPrimitiveType.Point: {\n                if (undefined !== mesh.primitive.polylines && !this.readPolylines(mesh.primitive.polylines, primitive, \"indices\", MeshPrimitiveType.Point === primitiveType))\n                    return undefined;\n                break;\n            }\n            default: {\n                assert(false, \"unhandled primitive type\");\n                return undefined;\n            }\n        }\n        if (displayParams.textureMapping && !mesh.uvs)\n            return undefined;\n        if (primitive.extensions?.CESIUM_primitive_outline) {\n            const data = this.readBufferData32(primitive.extensions.CESIUM_primitive_outline, \"indices\");\n            if (data !== undefined) {\n                assert(0 === data.count % 2);\n                mesh.primitive.edges = new MeshEdges();\n                for (let i = 0; i < data.count;)\n                    mesh.primitive.edges.visible.push(new MeshEdge(data.buffer[i++], data.buffer[i++]));\n            }\n        }\n        return mesh;\n    }\n    readPointCloud(primitive, hasFeatures) {\n        const posView = this.getBufferView(primitive.attributes, \"POSITION\");\n        if (!posView || GltfDataType.Float !== posView.type)\n            return undefined;\n        const posData = posView.toBufferData(GltfDataType.Float);\n        if (!(posData?.buffer instanceof Float32Array))\n            return undefined;\n        const colorView = this.getBufferView(primitive.attributes, \"COLOR_0\");\n        if (!colorView || GltfDataType.UnsignedByte !== colorView.type)\n            return undefined;\n        const colorData = colorView.toBufferData(GltfDataType.UnsignedByte);\n        if (!(colorData?.buffer instanceof Uint8Array))\n            return undefined;\n        const strideSkip = posView.stride - 3;\n        const pointRange = new Range3d();\n        for (let i = 0; i < posData.buffer.length; i += strideSkip)\n            pointRange.extendXYZ(posData.buffer[i++], posData.buffer[i++], posData.buffer[i++]);\n        let colors = colorData.buffer;\n        if (\"VEC4\" === colorView.accessor.type) {\n            // ###TODO support transparent point clouds\n            colors = new Uint8Array(colorData.count * 3);\n            for (let i = 0; i < colorData.count; i++) {\n                const srcIdx = colorView.stride * i;\n                const dstIdx = 3 * i;\n                for (let j = 0; j < 3; j++)\n                    colors[dstIdx + j] = colorData.buffer[srcIdx + j];\n            }\n        }\n        const features = new FeatureIndex();\n        if (hasFeatures)\n            features.type = FeatureIndexType.Uniform;\n        this._containsPointCloud = true;\n        return {\n            type: \"pointcloud\",\n            positions: posData.buffer,\n            qparams: QParams3d.fromOriginAndScale(new Point3d(0, 0, 0), new Point3d(1, 1, 1)),\n            pointRange,\n            colors,\n            colorFormat: \"rgb\",\n            features,\n            // ###TODO: If tile does not use additive refinement, compute voxelSize based on point range.\n            // Additive refinement is typical of the glTF point clouds we receive from Orbit.\n            voxelSize: 0,\n        };\n    }\n    readDracoMeshPrimitive(mesh, ext) {\n        const draco = this._dracoMeshes.get(ext);\n        if (!draco || \"triangle-list\" !== draco.topology)\n            return false;\n        const indices = draco.indices?.value;\n        if (!indices || (indices.length % 3) !== 0)\n            return false;\n        const pos = draco.attributes.POSITION?.value;\n        if (!pos || (pos.length % 3) !== 0)\n            return false;\n        // ###TODO: I have yet to see a draco-encoded mesh with interleaved attributes. Currently not checking.\n        const triangle = new Triangle();\n        for (let i = 0; i < indices.length; i += 3) {\n            triangle.setIndices(indices[i], indices[i + 1], indices[i + 2]);\n            mesh.addTriangle(triangle);\n        }\n        let posRange;\n        const bbox = draco.header?.boundingBox;\n        if (bbox) {\n            posRange = Range3d.createXYZXYZ(bbox[0][0], bbox[0][1], bbox[0][2], bbox[1][0], bbox[1][1], bbox[1][2]);\n        }\n        else {\n            posRange = Range3d.createNull();\n            for (let i = 0; i < pos.length; i += 3)\n                posRange.extendXYZ(pos[i], pos[i + 1], pos[i + 2]);\n        }\n        assert(mesh.points instanceof QPoint3dList);\n        mesh.points.params.setFromRange(posRange);\n        const pt = Point3d.createZero();\n        for (let i = 0; i < pos.length; i += 3) {\n            pt.set(pos[i], pos[i + 1], pos[i + 2]);\n            mesh.points.add(pt);\n        }\n        const normals = draco.attributes.NORMAL?.value;\n        if (normals && (normals.length % 3) === 0) {\n            const vec = Vector3d.createZero();\n            for (let i = 0; i < normals.length; i += 3) {\n                vec.set(normals[i], normals[i + 1], normals[i + 2]);\n                mesh.normals.push(OctEncodedNormal.fromVector(vec));\n            }\n        }\n        const uvs = draco.attributes.TEXCOORD_0?.value;\n        if (uvs && (uvs.length % 2) === 0)\n            for (let i = 0; i < uvs.length; i += 2)\n                mesh.uvParams.push(new Point2d(uvs[i], uvs[i + 1]));\n        const batchIds = draco.attributes._BATCHID?.value;\n        if (batchIds && mesh.features) {\n            const featureIndices = [];\n            for (const batchId of batchIds)\n                featureIndices.push(batchId);\n            mesh.features.setIndices(featureIndices);\n        }\n        return true;\n    }\n    deduplicateVertices(mesh) {\n        if (!mesh.points || !mesh.indices)\n            return false;\n        const numPoints = mesh.indices.length;\n        assert(0 === numPoints % 3);\n        const indices = mesh.indices;\n        if (indices instanceof Uint16Array && numPoints > 0xffff)\n            mesh.indices = new Uint32Array(numPoints);\n        else if (indices instanceof Uint8Array && numPoints > 0xff)\n            mesh.indices = new Uint32Array(numPoints);\n        const points = new Uint16Array(3 * numPoints);\n        const normals = mesh.normals ? new Uint16Array(numPoints) : undefined;\n        const uvs = mesh.uvs ? new Uint16Array(2 * numPoints) : undefined;\n        for (let i = 0; i < numPoints; i++) {\n            const index = indices[i];\n            mesh.indices[i] = i;\n            points[i * 3 + 0] = mesh.points[index * 3 + 0];\n            points[i * 3 + 1] = mesh.points[index * 3 + 1];\n            points[i * 3 + 2] = mesh.points[index * 3 + 2];\n            if (normals)\n                normals[i] = mesh.normals[index];\n            if (uvs) {\n                uvs[i * 2 + 0] = mesh.uvs[index * 2 + 0];\n                uvs[i * 2 + 1] = mesh.uvs[index * 2 + 1];\n            }\n        }\n        mesh.points = points;\n        mesh.normals = normals;\n        mesh.uvs = uvs;\n        return true;\n    }\n    /**\n     *\n     * @param positions quantized points\n     * @param primitive input json\n     * @param pseudoRtcBias a bias applied to each point - this is a workaround for tiles generated by\n     * context capture which have a large offset from the tileset origin that exceeds the\n     * capacity of 32 bit integers. This is essentially an ad hoc RTC applied at read time.\n     */\n    readVertices(mesh, primitive, pseudoRtcBias) {\n        const view = this.getBufferView(primitive.attributes, \"POSITION\");\n        if (undefined === view)\n            return false;\n        if (GltfDataType.Float === view.type) {\n            const buffer = view.toBufferData(GltfDataType.Float);\n            if (undefined === buffer)\n                return false;\n            const strideSkip = view.stride - 3;\n            mesh.pointRange = Range3d.createNull();\n            for (let i = 0; i < buffer.buffer.length; i += strideSkip)\n                mesh.pointRange.extendXYZ(buffer.buffer[i++], buffer.buffer[i++], buffer.buffer[i++]);\n            const positions = new QPoint3dList(QParams3d.fromRange(mesh.pointRange));\n            const scratchPoint = new Point3d();\n            for (let i = 0, j = 0; i < buffer.count; i++, j += strideSkip) {\n                scratchPoint.set(buffer.buffer[j++], buffer.buffer[j++], buffer.buffer[j++]);\n                if (undefined !== pseudoRtcBias)\n                    scratchPoint.subtractInPlace(pseudoRtcBias);\n                positions.add(scratchPoint);\n            }\n            mesh.pointQParams = positions.params;\n            mesh.points = positions.toTypedArray();\n        }\n        else {\n            if (GltfDataType.UnsignedShort !== view.type)\n                return false;\n            const quantized = view.accessor.extensions?.WEB3D_quantized_attributes;\n            const rangeMin = quantized?.decodedMin;\n            const rangeMax = quantized?.decodedMax;\n            if (!rangeMin || !rangeMax) // required by spec...\n                return false;\n            // ###TODO apply WEB3D_quantized_attributes.decodeMatrix? Have not encountered in the wild; glTF 1.0 only.\n            const buffer = view.toBufferData(GltfDataType.UnsignedShort);\n            if (undefined === buffer || !(buffer.buffer instanceof Uint16Array))\n                return false;\n            assert(buffer.buffer instanceof Uint16Array);\n            mesh.pointRange = Range3d.createXYZXYZ(rangeMin[0], rangeMin[1], rangeMin[2], rangeMax[0], rangeMax[1], rangeMax[2]);\n            if (undefined !== pseudoRtcBias) {\n                mesh.pointRange.low.subtractInPlace(pseudoRtcBias);\n                mesh.pointRange.high.subtractInPlace(pseudoRtcBias);\n            }\n            mesh.pointQParams = QParams3d.fromRange(mesh.pointRange);\n            if (3 === view.stride) {\n                mesh.points = buffer.buffer;\n            }\n            else {\n                mesh.points = new Uint16Array(3 * view.count);\n                for (let i = 0, j = 0; i < view.count; i++) {\n                    const index = i * view.stride;\n                    mesh.points[j++] = buffer.buffer[index];\n                    mesh.points[j++] = buffer.buffer[index + 1];\n                    mesh.points[j++] = buffer.buffer[index + 2];\n                }\n            }\n        }\n        return true;\n    }\n    readIndices(json, accessorName) {\n        const data = this.readBufferData32(json, accessorName);\n        if (undefined === data)\n            return undefined;\n        const indices = [];\n        for (let i = 0; i < data.count; i++)\n            indices.push(data.buffer[i]);\n        return indices;\n    }\n    readBatchTable(_mesh, _json) {\n    }\n    readPrimitiveFeatures(_primitive) {\n        return undefined;\n    }\n    readMeshIndices(mesh, json) {\n        if (undefined !== json.indices) {\n            const data = this.readBufferData16(json, \"indices\") || this.readBufferData32(json, \"indices\");\n            if (data && (data.buffer instanceof Uint8Array || data.buffer instanceof Uint16Array || data.buffer instanceof Uint32Array)) {\n                mesh.indices = data.buffer;\n                return true;\n            }\n            return false;\n        }\n        // Non-indexed geometry. Manufacture triangle indices from points.\n        const numPoints = mesh.points?.length;\n        if (undefined === numPoints || 0 !== numPoints % 3)\n            return false;\n        mesh.indices = numPoints < 255 ? new Uint8Array(numPoints) : (numPoints < 0xffff ? new Uint16Array(numPoints) : new Uint32Array(numPoints));\n        for (let i = 0; i < numPoints; i++)\n            mesh.indices[i] = i;\n        return true;\n    }\n    readNormals(mesh, json, accessorName) {\n        const view = this.getBufferView(json, accessorName);\n        if (undefined === view)\n            return false;\n        switch (view.type) {\n            case GltfDataType.Float: {\n                const data = view.toBufferData(GltfDataType.Float);\n                if (undefined === data)\n                    return false;\n                mesh.normals = new Uint16Array(data.count);\n                const scratchNormal = new Vector3d();\n                const strideSkip = view.stride - 3;\n                for (let i = 0, j = 0; i < data.count; i++, j += strideSkip) {\n                    scratchNormal.set(data.buffer[j++], data.buffer[j++], data.buffer[j++]);\n                    mesh.normals[i] = OctEncodedNormal.encode(scratchNormal);\n                }\n                return true;\n            }\n            case GltfDataType.UnsignedByte: {\n                const data = view.toBufferData(GltfDataType.UnsignedByte);\n                if (undefined === data)\n                    return false;\n                // ###TODO: we shouldn't have to allocate OctEncodedNormal objects...just use uint16s / numbers...\n                mesh.normals = new Uint16Array(data.count);\n                for (let i = 0; i < data.count; i++) {\n                    // ###TODO? not clear why ray writes these as pairs of uint8...\n                    const index = i * view.stride;\n                    const normal = data.buffer[index] | (data.buffer[index + 1] << 8);\n                    mesh.normals[i] = normal;\n                }\n                return true;\n            }\n            default:\n                return false;\n        }\n    }\n    readColors(mesh, attribute, accessorName) {\n        const view = this.getBufferView(attribute, accessorName);\n        if (!view || (GltfDataType.Float !== view.type && GltfDataType.UnsignedByte !== view.type && GltfDataType.SignedByte !== view.type))\n            return false;\n        const data = view.toBufferData(view.type);\n        if (!data)\n            return false;\n        const hasAlpha = \"VEC4\" === view.accessor.type;\n        const factor = view.type === GltfDataType.Float ? 255 : 1;\n        const rgbt = new Uint8Array(4);\n        const color = new Uint32Array(rgbt.buffer);\n        for (let i = 0; i < data.count; i++) {\n            const index = view.stride * i;\n            rgbt[0] = data.buffer[index] * factor;\n            rgbt[1] = data.buffer[index + 1] * factor;\n            rgbt[2] = data.buffer[index + 2] * factor;\n            rgbt[3] = hasAlpha ? (255 - data.buffer[index + 3] * factor) : 0;\n            mesh.primitive.colors.push(mesh.primitive.colorMap.insert(color[0]));\n        }\n        return true;\n    }\n    readUVParams(mesh, json, accessorName) {\n        const view = this.getBufferView(json, accessorName);\n        if (view === undefined)\n            return false;\n        switch (view.type) {\n            case GltfDataType.Float: {\n                const data = this.readBufferDataFloat(json, accessorName);\n                if (!data)\n                    return false;\n                mesh.uvRange = Range2d.createNull();\n                for (let i = 0; i < data.count; i++) {\n                    const index = view.stride * i; // 2 float per param...\n                    mesh.uvRange.extendXY(data.buffer[index], data.buffer[index + 1]);\n                }\n                mesh.uvQParams = QParams2d.fromRange(mesh.uvRange);\n                mesh.uvs = new Uint16Array(data.count * 2);\n                for (let i = 0, j = 0; i < data.count; i++) {\n                    const index = view.stride * i; // 2 float per param...\n                    mesh.uvs[j++] = Quantization.quantize(data.buffer[index], mesh.uvQParams.origin.x, mesh.uvQParams.scale.x);\n                    mesh.uvs[j++] = Quantization.quantize(data.buffer[index + 1], mesh.uvQParams.origin.y, mesh.uvQParams.scale.y);\n                }\n                return true;\n            }\n            case GltfDataType.UnsignedShort: {\n                const quantized = view.accessor.extensions?.WEB3D_quantized_attributes;\n                const rangeMin = quantized?.decodedMin;\n                const rangeMax = quantized?.decodedMax;\n                if (undefined === rangeMin || undefined === rangeMax)\n                    return false;\n                const qData = view.toBufferData(GltfDataType.UnsignedShort);\n                if (undefined === qData || !(qData.buffer instanceof Uint16Array))\n                    return false;\n                mesh.uvRange = Range2d.createXYXY(rangeMin[0], rangeMin[1], rangeMax[0], rangeMax[1]);\n                mesh.uvQParams = QParams2d.fromRange(mesh.uvRange);\n                if (2 === view.stride) {\n                    mesh.uvs = qData.buffer;\n                }\n                else {\n                    mesh.uvs = new Uint16Array(2 * view.count);\n                    for (let i = 0, j = 0; i < view.count; i++) {\n                        const index = i * view.stride;\n                        mesh.uvs[j++] = qData.buffer[index];\n                        mesh.uvs[j++] = qData.buffer[index + 1];\n                    }\n                }\n                return true;\n            }\n            default:\n                assert(false);\n                return false;\n        }\n        return true;\n    }\n    readPolylines(polylines, json, accessorName, disjoint) {\n        const data = this.readBufferData32(json, accessorName);\n        if (undefined === data)\n            return false;\n        const indices = new Array();\n        if (disjoint) {\n            for (let i = 0; i < data.count;)\n                indices.push(data.buffer[i++]);\n        }\n        else {\n            for (let i = 0; i < data.count;) {\n                const index0 = data.buffer[i++];\n                const index1 = data.buffer[i++];\n                if (0 === indices.length || index0 !== indices[indices.length - 1]) {\n                    if (indices.length !== 0) {\n                        polylines.push(new MeshPolyline(indices));\n                        indices.length = 0;\n                    }\n                    indices.push(index0);\n                }\n                indices.push(index1);\n            }\n        }\n        if (indices.length !== 0)\n            polylines.push(new MeshPolyline(indices));\n        return true;\n    }\n    async resolveResources() {\n        // Load any external images and buffers.\n        await this._resolveResources();\n        // If any meshes are draco-compressed, dynamically load the decoder module and then decode the meshes.\n        const dracoMeshes = [];\n        for (const node of this.traverseScene()) {\n            for (const meshId of getGltfNodeMeshIds(node)) {\n                const mesh = this._meshes[meshId];\n                if (mesh?.primitives)\n                    for (const primitive of mesh.primitives)\n                        if (primitive.extensions?.KHR_draco_mesh_compression)\n                            dracoMeshes.push(primitive.extensions.KHR_draco_mesh_compression);\n            }\n        }\n        if (dracoMeshes.length === 0)\n            return;\n        try {\n            const dracoLoader = (await __vitePreload(() => import(\"@loaders.gl/draco\"),__VITE_IS_MODERN__?\"__VITE_PRELOAD__\":void 0)).DracoLoader;\n            await Promise.all(dracoMeshes.map(async (x) => this.decodeDracoMesh(x, dracoLoader)));\n        }\n        catch (err) {\n            Logger.logWarning(FrontendLoggerCategory.Render, \"Failed to decode draco-encoded glTF mesh\");\n            Logger.logException(FrontendLoggerCategory.Render, err);\n        }\n    }\n    async _resolveResources() {\n        // ###TODO traverse the scene nodes to find resources referenced by them, instead of resolving everything - some resources may not\n        // be required for the scene.\n        const promises = [];\n        try {\n            for (const buffer of gltfDictionaryIterator(this._buffers))\n                if (!buffer.resolvedBuffer)\n                    promises.push(this.resolveBuffer(buffer));\n            await Promise.all(promises);\n            if (this._isCanceled)\n                return;\n            promises.length = 0;\n            for (const image of gltfDictionaryIterator(this._images))\n                if (!image.resolvedImage)\n                    promises.push(this.resolveImage(image));\n            await Promise.all(promises);\n        }\n        catch (_) {\n        }\n    }\n    async decodeDracoMesh(ext, loader) {\n        const bv = this._bufferViews[ext.bufferView];\n        if (!bv || !bv.byteLength)\n            return;\n        let buf = this._buffers[bv.buffer]?.resolvedBuffer;\n        if (!buf)\n            return;\n        const offset = bv.byteOffset ?? 0;\n        buf = buf.subarray(offset, offset + bv.byteLength);\n        const mesh = await loader.parse(buf, {}); // NB: `options` argument declared optional but will produce exception if not supplied.\n        if (mesh)\n            this._dracoMeshes.set(ext, mesh);\n    }\n    resolveUrl(uri) {\n        try {\n            const resolved = new URL(uri, this._baseUrl);\n            resolved.search = this._baseUrl?.search ?? \"\";\n            return resolved.toString();\n        }\n        catch (_) {\n            return undefined;\n        }\n    }\n    async resolveBuffer(buffer) {\n        if (buffer.resolvedBuffer || undefined === buffer.uri)\n            return;\n        try {\n            const url = this.resolveUrl(buffer.uri);\n            const response = url ? await fetch(url) : undefined;\n            if (this._isCanceled)\n                return;\n            const data = await response?.arrayBuffer();\n            if (this._isCanceled)\n                return;\n            if (data)\n                buffer.resolvedBuffer = new Uint8Array(data);\n        }\n        catch (_) {\n            //\n        }\n    }\n    async resolveImage(image) {\n        if (image.resolvedImage)\n            return;\n        const bvSrc = undefined !== image.bufferView ? image : image.extensions?.KHR_binary_glTF;\n        if (undefined !== bvSrc?.bufferView) {\n            const format = undefined !== bvSrc.mimeType ? getImageSourceFormatForMimeType(bvSrc.mimeType) : undefined;\n            const bufferView = this._bufferViews[bvSrc.bufferView];\n            if (undefined === format || !bufferView || !bufferView.byteLength || bufferView.byteLength < 0)\n                return;\n            const bufferData = this._buffers[bufferView.buffer]?.resolvedBuffer;\n            if (!bufferData)\n                return;\n            const offset = bufferView.byteOffset ?? 0;\n            const bytes = bufferData.subarray(offset, offset + bufferView.byteLength);\n            try {\n                const imageSource = new ImageSource(bytes, format);\n                if (this._system.supportsCreateImageBitmap)\n                    image.resolvedImage = await imageBitmapFromImageSource(imageSource);\n                else\n                    image.resolvedImage = await imageElementFromImageSource(imageSource);\n            }\n            catch (_) {\n                //\n            }\n            return;\n        }\n        const url = undefined !== image.uri ? this.resolveUrl(image.uri) : undefined;\n        if (undefined !== url)\n            image.resolvedImage = await tryImageElementFromUrl(url);\n    }\n    /** Exposed strictly for testing. */\n    getTextureType(sampler) {\n        // ###TODO: RenderTexture currently does not support different wrapping behavior for U vs V, nor does it support mirrored repeat.\n        let wrapS = sampler?.wrapS;\n        let wrapT = sampler?.wrapT;\n        if (undefined === wrapS && undefined === wrapT)\n            wrapS = wrapT = this.defaultWrapMode;\n        if (GltfWrapMode.ClampToEdge === wrapS || GltfWrapMode.ClampToEdge === wrapT)\n            return RenderTexture.Type.TileSection;\n        return RenderTexture.Type.Normal;\n    }\n    resolveTexture(textureId, isTransparent) {\n        const texture = this._textures[textureId];\n        if (!texture || undefined === texture.source)\n            return false;\n        const image = this._images[texture.source]?.resolvedImage;\n        if (!image)\n            return false;\n        const samplerId = texture.sampler;\n        const sampler = undefined !== samplerId ? this._samplers[samplerId] : undefined;\n        const textureType = this.getTextureType(sampler);\n        const renderTexture = this._system.createTexture({\n            type: textureType,\n            image: {\n                source: image,\n                transparency: isTransparent ? TextureTransparency.Mixed : TextureTransparency.Opaque,\n            },\n        });\n        return renderTexture ?? false;\n    }\n    findTextureMapping(id, isTransparent, normalMapId) {\n        if (undefined === id && undefined === normalMapId)\n            return undefined;\n        let texture;\n        if (undefined !== id) {\n            texture = this._resolvedTextures.get({ id, isTransparent });\n            if (undefined === texture)\n                this._resolvedTextures.set({ id, isTransparent }, texture = this.resolveTexture(id, isTransparent));\n        }\n        let normalMap;\n        if (undefined !== normalMapId) {\n            normalMap = this._resolvedTextures.get({ id: normalMapId, isTransparent: false });\n            if (undefined === normalMap)\n                this._resolvedTextures.set({ id: normalMapId, isTransparent: false }, normalMap = this.resolveTexture(normalMapId, false));\n        }\n        let nMap;\n        if (normalMap) {\n            const greenUp = true;\n            if (texture) {\n                nMap = {\n                    normalMap,\n                    greenUp,\n                };\n            }\n            else {\n                texture = normalMap;\n                nMap = { greenUp };\n            }\n        }\n        if (!texture)\n            return undefined;\n        const textureMapping = new TextureMapping(texture, new TextureMapping.Params());\n        textureMapping.normalMapParams = nMap;\n        return textureMapping;\n    }\n}\n/** Produce a [[RenderGraphic]] from a [glTF](https://www.khronos.org/gltf/) asset suitable for use in [view decorations]($docs/learning/frontend/ViewDecorations).\n * @returns a graphic produced from the glTF asset's default scene, or `undefined` if a graphic could not be produced from the asset.\n * @note Support for the full [glTF 2.0 specification](https://www.khronos.org/registry/glTF/specs/2.0/glTF-2.0.html) is currently a work in progress.\n * If a particular glTF asset fails to load and/or display properly, please\n * [submit an issue](https://github.com/iTwin/itwinjs-core/issues).\n * @see [Example decorator]($docs/learning/frontend/ViewDecorations#gltf-decorations) for an example of a decorator that reads and displays a glTF asset.\n * @see [[readGltf]] to obtain more information about the glTF model.\n * @public\n * @extensions\n */\nexport async function readGltfGraphics(args) {\n    const result = await readGltf(args);\n    return result?.graphic;\n}\n/** Produce a [[RenderGraphic]] from a [glTF](https://www.khronos.org/gltf/) asset suitable for use in [view decorations]($docs/learning/frontend/ViewDecorations).\n * @returns a graphic produced from the glTF asset's default scene, or `undefined` if a graphic could not be produced from the asset.\n * The returned graphic also includes the bounding boxes of the glTF model in world and local coordiantes.\n * @note Support for the full [glTF 2.0 specification](https://www.khronos.org/registry/glTF/specs/2.0/glTF-2.0.html) is currently a work in progress.\n * If a particular glTF asset fails to load and/or display properly, please\n * [submit an issue](https://github.com/iTwin/itwinjs-core/issues).\n * @see [Example decorator]($docs/learning/frontend/ViewDecorations#gltf-decorations) for an example of a decorator that reads and displays a glTF asset.\n * @public\n */\nexport async function readGltf(args) {\n    const baseUrl = typeof args.baseUrl === \"string\" ? new URL(args.baseUrl) : args.baseUrl;\n    const props = GltfReaderProps.create(args.gltf, true, baseUrl); // glTF supports exactly one coordinate system with y axis up.\n    const reader = props ? new GltfGraphicsReader(props, args) : undefined;\n    if (!reader)\n        return undefined;\n    const result = await reader.read();\n    if (!result.graphic)\n        return undefined;\n    assert(result.contentRange !== undefined, \"readGltf always computes content range\");\n    assert(result.range !== undefined, \"readGltf always computes world range\");\n    return {\n        graphic: result.graphic,\n        localBoundingBox: result.contentRange ?? Range3d.createNull(),\n        boundingBox: result.range ?? Range3d.createNull(),\n    };\n}\n/** Implements [[readGltfGraphics]]. Exported strictly for tests.\n * @internal\n */\nexport class GltfGraphicsReader extends GltfReader {\n    constructor(props, args) {\n        super({\n            props,\n            iModel: args.iModel,\n            vertexTableRequired: true,\n        });\n        this._contentRange = args.contentRange;\n        this._transform = args.transform;\n        this._isLeaf = true !== args.hasChildren;\n        this.binaryData = props.binaryData;\n        const pickableId = args.pickableOptions?.id;\n        if (pickableId) {\n            this._featureTable = new FeatureTable(1, args.pickableOptions?.modelId ?? pickableId, BatchType.Primary);\n            this._featureTable.insert(new Feature(pickableId));\n        }\n    }\n    async read() {\n        await this.resolveResources();\n        return this.readGltfAndCreateGraphics(this._isLeaf, this._featureTable, this._contentRange, this._transform);\n    }\n    get nodes() { return this._nodes; }\n    get scenes() { return this._glTF.scenes ?? emptyDict; }\n    get sceneNodes() { return this._sceneNodes; }\n    get textures() { return this._textures; }\n}\n//# sourceMappingURL=GltfReader.js.map",
      "start": 1693508121755,
      "end": 1693508121756,
      "order": "normal",
      "sourcemaps": null
    }
  ]
}
